{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxJSDuJ986IZ",
        "outputId": "737aa3f0-937f-4b42-aa58-32017c38d03b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install inltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6B67TOte9ECr",
        "outputId": "63e3ca0e-3792-477f-cbab-4097caf1adff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting inltk\n",
            "  Downloading inltk-0.9-py3-none-any.whl (13 kB)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.98-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from inltk) (23.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from inltk) (3.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from inltk) (1.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from inltk) (2.27.1)\n",
            "Collecting fastai==1.0.57\n",
            "  Downloading fastai-1.0.57-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.3/233.3 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numexpr in /usr/local/lib/python3.9/dist-packages (from inltk) (2.8.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from inltk) (4.11.2)\n",
            "Collecting typing\n",
            "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting async-timeout>=3.0.1\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting bottleneck\n",
            "  Downloading Bottleneck-1.3.7-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (353 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.1/353.1 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastprogress>=0.1.19 in /usr/local/lib/python3.9/dist-packages (from inltk) (1.0.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from inltk) (6.0)\n",
            "Requirement already satisfied: spacy>=2.0.18 in /usr/local/lib/python3.9/dist-packages (from inltk) (3.5.1)\n",
            "Collecting nvidia-ml-py3\n",
            "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from inltk) (8.4.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.9/dist-packages (from inltk) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from inltk) (1.10.1)\n",
            "Collecting aiohttp>=3.5.4\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from fastai==1.0.57->inltk) (0.15.1+cu118)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from fastai==1.0.57->inltk) (2.0.0+cu118)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp>=3.5.4->inltk) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp>=3.5.4->inltk) (22.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.0.18->inltk) (1.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy>=2.0.18->inltk) (67.6.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.0.18->inltk) (8.1.9)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.0.18->inltk) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.0.18->inltk) (4.65.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.0.18->inltk) (0.10.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.0.18->inltk) (1.10.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.0.18->inltk) (3.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.0.18->inltk) (2.0.7)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.0.18->inltk) (0.7.0)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.0.18->inltk) (1.1.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.0.18->inltk) (1.0.9)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.0.18->inltk) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.0.18->inltk) (2.0.8)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.0.18->inltk) (3.0.12)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.0.18->inltk) (3.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.0.18->inltk) (3.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->inltk) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->inltk) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->inltk) (3.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->inltk) (2.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->inltk) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->inltk) (3.0.9)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->inltk) (5.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->inltk) (4.39.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->inltk) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->inltk) (0.11.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->inltk) (1.0.7)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->inltk) (2022.7.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->inltk) (3.15.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy>=2.0.18->inltk) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->inltk) (1.16.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=2.0.18->inltk) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=2.0.18->inltk) (0.0.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.0->fastai==1.0.57->inltk) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.0->fastai==1.0.57->inltk) (3.11.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.0->fastai==1.0.57->inltk) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.0->fastai==1.0.57->inltk) (3.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.0.0->fastai==1.0.57->inltk) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.0.0->fastai==1.0.57->inltk) (3.25.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy>=2.0.18->inltk) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy>=2.0.18->inltk) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.0.0->fastai==1.0.57->inltk) (1.3.0)\n",
            "Building wheels for collected packages: nvidia-ml-py3, typing\n",
            "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19188 sha256=72a910462040e6e9ca8c916387eaef4cc3dcac5f403ceb3e4f51ffd70620fbfb\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/d8/b0/15cfd7805d39250ac29318105f09b1750683387630d68423e1\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26321 sha256=7e704e530d67143722d67825090edf626205270b399a95bb88f6e2b851f67095\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/17/1f/332799f975d1b2d7f9b3f33bbccf65031e794717d24432caee\n",
            "Successfully built nvidia-ml-py3 typing\n",
            "Installing collected packages: sentencepiece, nvidia-ml-py3, typing, multidict, frozenlist, bottleneck, async-timeout, yarl, aiosignal, aiohttp, fastai, inltk\n",
            "  Attempting uninstall: fastai\n",
            "    Found existing installation: fastai 2.7.12\n",
            "    Uninstalling fastai-2.7.12:\n",
            "      Successfully uninstalled fastai-2.7.12\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 bottleneck-1.3.7 fastai-1.0.57 frozenlist-1.3.3 inltk-0.9 multidict-6.0.4 nvidia-ml-py3-7.352.0 sentencepiece-0.1.98 typing-3.7.4.3 yarl-1.8.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data=pd.read_csv('drive/MyDrive/nlp_proj/train_data.csv')\n",
        "df=data\n",
        "data['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lggDYpAg9Hv-",
        "outputId": "3746e4fc-d366-4d96-9679-959ccf505794"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                            भीड़ में  बहुत  हब्सी मिलेंगे\n",
              "1                साले बेवकूफ अपनी मां मक्खियां  तो हटा दें\n",
              "2                         बुर देदो तो मुह में लंड ले लो तो\n",
              "3                     कुत्ता वहा है चिल्ला तू क्यों रहा है\n",
              "4                चाय नहीं पीता हूं मैं इसी को छोड़ दिया ok\n",
              "                               ...                        \n",
              "20178               और छोटे भी क्यु पहनते हो, कहा जरूरत है\n",
              "20179               कैसी हो सोना क्या आप हमसे दोस्ती करोगी\n",
              "20180            इस से ये पता चलता है अब चुनाव आ रहा है🙄🙄🙄\n",
              "20181                      खेत जोते हुए किसान भैंस के साथो\n",
              "20182    काश आगर यह इतना दिमाग पढाई में लगायें तो शायद ...\n",
              "Name: text, Length: 20183, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "j7elavKe9Jbl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emoj = re.compile(\"[\"\n",
        "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "    u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "    u\"\\U00002702-\\U000027B0\"\n",
        "    u\"\\U00002702-\\U000027B0\"\n",
        "    u\"\\U000024C2-\\U0001F251\"\n",
        "    u\"\\U0001f926-\\U0001f937\"\n",
        "    u\"\\U00010000-\\U0010ffff\"\n",
        "    u\"\\u2640-\\u2642\" \n",
        "    u\"\\u2600-\\u2B55\"\n",
        "    u\"\\u200d\"\n",
        "    u\"\\u23cf\"\n",
        "    u\"\\u23e9\"\n",
        "    u\"\\u231a\"\n",
        "    u\"\\ufe0f\"  # dingbats\n",
        "    u\"\\u3030\"\n",
        "                  \"]+\", re.UNICODE)\n",
        "for i in range(len(data)):\n",
        "    data['text'][i] = emoj.sub(r'', data['text'][i])\n",
        "# count_length()\n",
        "data.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "50DLQUYV9OtY",
        "outputId": "4c1c9a64-5710-46e9-b60e-23990dc65ea3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-7309bf5b9701>:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['text'][i] = emoj.sub(r'', data['text'][i])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    label                                               text\n",
              "0       0                      भीड़ में  बहुत  हब्सी मिलेंगे\n",
              "1       0          साले बेवकूफ अपनी मां मक्खियां  तो हटा दें\n",
              "2       0                   बुर देदो तो मुह में लंड ले लो तो\n",
              "3       0               कुत्ता वहा है चिल्ला तू क्यों रहा है\n",
              "4       1          चाय नहीं पीता हूं मैं इसी को छोड़ दिया ok\n",
              "5       0  बैंकों से सरकार का रिश्ता दलाली का है, बड़े बड...\n",
              "6       0  #पगली  हम तो #बहोत  _शोकीन हैं  #तुजे डोली मे ...\n",
              "7       0  ohh my god . यहां इतने सारे चमचे इसका मतलब जलन...\n",
              "8       1        आप मेरे कमेंट का इतना  इंतजार क्यों करते है\n",
              "9       0                              भोसड़ी को बात करने दो\n",
              "10      1                              आप बहुत प्यारे हो सनम\n",
              "11      0  हमें   परमात्मा की   भक्ति   करनी    चाहिए   न...\n",
              "12      0                      ये बीजेपी वाले बहुत चूतिया है\n",
              "13      1  तुम्हारे पीछे पड़े हैं  बहुत सारे नमूने हैं   ...\n",
              "14      0                                तेरि माँ किचुत सालि\n",
              "15      1                           सुपर वेरी गुड काला चश्मा\n",
              "16      0  सूचियां इतनी सेक्सी हैं चूत कितनी मस्त होगी तु...\n",
              "17      1                           सुंदर दिसतेस तू नाद खुळा\n",
              "18      1                 नाक क्लीन हो जाता क्या ऐसा करने से\n",
              "19      0  कोई भी धक्का मुक्की नहीं करेंगा सभी को गाली दे..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd724108-d9e5-4cd0-a12c-4a63fbe7567a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>भीड़ में  बहुत  हब्सी मिलेंगे</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>साले बेवकूफ अपनी मां मक्खियां  तो हटा दें</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>बुर देदो तो मुह में लंड ले लो तो</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>कुत्ता वहा है चिल्ला तू क्यों रहा है</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>चाय नहीं पीता हूं मैं इसी को छोड़ दिया ok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>बैंकों से सरकार का रिश्ता दलाली का है, बड़े बड...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>#पगली  हम तो #बहोत  _शोकीन हैं  #तुजे डोली मे ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>ohh my god . यहां इतने सारे चमचे इसका मतलब जलन...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>आप मेरे कमेंट का इतना  इंतजार क्यों करते है</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>भोसड़ी को बात करने दो</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>आप बहुत प्यारे हो सनम</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>हमें   परमात्मा की   भक्ति   करनी    चाहिए   न...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>ये बीजेपी वाले बहुत चूतिया है</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>तुम्हारे पीछे पड़े हैं  बहुत सारे नमूने हैं   ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>तेरि माँ किचुत सालि</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>सुपर वेरी गुड काला चश्मा</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>सूचियां इतनी सेक्सी हैं चूत कितनी मस्त होगी तु...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>सुंदर दिसतेस तू नाद खुळा</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>नाक क्लीन हो जाता क्या ऐसा करने से</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>कोई भी धक्का मुक्की नहीं करेंगा सभी को गाली दे...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd724108-d9e5-4cd0-a12c-4a63fbe7567a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd724108-d9e5-4cd0-a12c-4a63fbe7567a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd724108-d9e5-4cd0-a12c-4a63fbe7567a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['text'] =  [re.sub(r'[?|$|.|!|।|,|:|;|]','', str(x)) for x in data['text']]\n",
        "data['totalwords'] = data['text'].str.split().str.len()\n",
        "data.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "hNHg3dnE9RlE",
        "outputId": "ec768533-6d95-4277-e9bf-6925b1545bec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    label                                               text  totalwords\n",
              "0       0                      भीड़ में  बहुत  हब्सी मिलेंगे           5\n",
              "1       0          साले बेवकूफ अपनी मां मक्खियां  तो हटा दें           8\n",
              "2       0                   बुर देदो तो मुह में लंड ले लो तो           9\n",
              "3       0               कुत्ता वहा है चिल्ला तू क्यों रहा है           8\n",
              "4       1          चाय नहीं पीता हूं मैं इसी को छोड़ दिया ok          10\n",
              "5       0  बैंकों से सरकार का रिश्ता दलाली का है बड़े बड़...          28\n",
              "6       0  #पगली  हम तो #बहोत  _शोकीन हैं  #तुजे डोली मे ...          30\n",
              "7       0  ohh my god  यहां इतने सारे चमचे इसका मतलब जलनख...          14\n",
              "8       1        आप मेरे कमेंट का इतना  इंतजार क्यों करते है           9\n",
              "9       0                              भोसड़ी को बात करने दो           5\n",
              "10      1                              आप बहुत प्यारे हो सनम           5\n",
              "11      0  हमें   परमात्मा की   भक्ति   करनी    चाहिए   न...          13\n",
              "12      0                      ये बीजेपी वाले बहुत चूतिया है           6\n",
              "13      1  तुम्हारे पीछे पड़े हैं  बहुत सारे नमूने हैं   ...          16\n",
              "14      0                                तेरि माँ किचुत सालि           4\n",
              "15      1                           सुपर वेरी गुड काला चश्मा           5\n",
              "16      0  सूचियां इतनी सेक्सी हैं चूत कितनी मस्त होगी तु...           9\n",
              "17      1                           सुंदर दिसतेस तू नाद खुळा           5\n",
              "18      1                 नाक क्लीन हो जाता क्या ऐसा करने से           8\n",
              "19      0  कोई भी धक्का मुक्की नहीं करेंगा सभी को गाली दे...          31"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff38c784-ef03-49a7-a107-9f1e4ca729e2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>totalwords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>भीड़ में  बहुत  हब्सी मिलेंगे</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>साले बेवकूफ अपनी मां मक्खियां  तो हटा दें</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>बुर देदो तो मुह में लंड ले लो तो</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>कुत्ता वहा है चिल्ला तू क्यों रहा है</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>चाय नहीं पीता हूं मैं इसी को छोड़ दिया ok</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>बैंकों से सरकार का रिश्ता दलाली का है बड़े बड़...</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>#पगली  हम तो #बहोत  _शोकीन हैं  #तुजे डोली मे ...</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>ohh my god  यहां इतने सारे चमचे इसका मतलब जलनख...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>आप मेरे कमेंट का इतना  इंतजार क्यों करते है</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>भोसड़ी को बात करने दो</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>आप बहुत प्यारे हो सनम</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>हमें   परमात्मा की   भक्ति   करनी    चाहिए   न...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>ये बीजेपी वाले बहुत चूतिया है</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>तुम्हारे पीछे पड़े हैं  बहुत सारे नमूने हैं   ...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>तेरि माँ किचुत सालि</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>सुपर वेरी गुड काला चश्मा</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>सूचियां इतनी सेक्सी हैं चूत कितनी मस्त होगी तु...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>सुंदर दिसतेस तू नाद खुळा</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>नाक क्लीन हो जाता क्या ऐसा करने से</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>कोई भी धक्का मुक्की नहीं करेंगा सभी को गाली दे...</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff38c784-ef03-49a7-a107-9f1e4ca729e2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff38c784-ef03-49a7-a107-9f1e4ca729e2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff38c784-ef03-49a7-a107-9f1e4ca729e2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum=data['totalwords'].sum() # total number of words in all sentences.\n",
        "n=df['totalwords'].count() # total number of sentences.\n",
        "aver_words=sum/n\n",
        "\n",
        "# Words tokenization of all sentences.\n",
        "lt = data[\"text\"].tolist()\n",
        "joint_words = ' '.join(lt)\n",
        "# tokens = nltk.word_tokenize(joint_words)"
      ],
      "metadata": {
        "id": "P8CyEZL-9Wkg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = data"
      ],
      "metadata": {
        "id": "qfwwT9Sl9YBJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stop_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HI6m-lr9eUh",
        "outputId": "ea0e7283-a8ff-4aef-841e-c1713425d961"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting stop_words\n",
            "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: stop_words\n",
            "  Building wheel for stop_words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop_words: filename=stop_words-2018.7.23-py3-none-any.whl size=32910 sha256=11f27416f72674dca2d43482669bd75b65e77607f76685abdc06bd505e7b716f\n",
            "  Stored in directory: /root/.cache/pip/wheels/da/d8/66/395317506a23a9d1d7de433ad6a7d9e6e16aab48cf028a0f60\n",
            "Successfully built stop_words\n",
            "Installing collected packages: stop_words\n",
            "Successfully installed stop_words-2018.7.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from stop_words import safe_get_stop_words\n",
        "\n",
        "# stop_words = safe_get_stop_words('hindi')\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "# print(stopwords.words('english'))\n",
        "sw=[\"अंदर\",\"अत\",\"अदि\",\"अप\",\"अपना\",\"अपनि\",\"अपनी\",\"अपने\",\"अभि\",\"अभी\",\"आदि\",\"आप\",\"इंहिं\",\"इंहें\",\"इंहों\",\"इतयादि\",\"इत्यादि\",\"इन\",\"इनका\",\"इन्हीं\",\"इन्हें\",\"इन्हों\",\"इस\",\"इसका\",\"इसकि\",\"इसकी\",\"इसके\",\"इसमें\",\"इसि\",\"इसी\",\"इसे\",\"उंहिं\",\"उंहें\",\"उंहों\",\"उन\",\"उनका\",\"उनकि\",\"उनकी\",\"उनके\",\"उनको\",\"उन्हीं\",\"उन्हें\",\"उन्हों\",\"उस\",\"उसके\",\"उसि\",\"उसी\",\"उसे\",\"एक\",\"एवं\",\"एस\",\"एसे\",\"ऐसे\",\"ओर\",\"और\",\"कइ\",\"कई\",\"कर\",\"करता\",\"करते\",\"करना\",\"करने\",\"करें\",\"कहते\",\"कहा\",\"का\",\"काफि\",\"काफ़ी\",\"कि\",\"किंहें\",\"किंहों\",\"कितना\",\"किन्हें\",\"किन्हों\",\"किया\",\"किर\",\"किस\",\"किसि\",\"किसी\",\"किसे\",\"की\",\"कुछ\",\"कुल\",\"के\",\"को\",\"कोइ\",\"कोई\",\"कोन\",\"कोनसा\",\"कौन\",\"कौनसा\",\"गया\",\"घर\",\"जब\",\"जहाँ\",\"जहां\",\"जा\",\"जिंहें\",\"जिंहों\",\"जितना\",\"जिधर\",\"जिन\",\"जिन्हें\",\"जिन्हों\",\"जिस\",\"जिसे\",\"जीधर\",\"जेसा\",\"जेसे\",\"जैसा\",\"जैसे\",\"जो\",\"तक\",\"तब\",\"तरह\",\"तिंहें\",\"तिंहों\",\"तिन\",\"तिन्हें\",\"तिन्हों\",\"तिस\",\"तिसे\",\"तो\",\"था\",\"थि\",\"थी\",\"थे\",\"दबारा\",\"दवारा\",\"दिया\",\"दुसरा\",\"दुसरे\",\"दूसरे\",\"दो\",\"द्वारा\",\"न\",\"नहिं\",\"नहीं\",\"ना\",\"निचे\",\"निहायत\",\"नीचे\",\"ने\",\"पर\",\"पहले\",\"पुरा\",\"पूरा\",\"पे\",\"फिर\",\"बनि\",\"बनी\",\"बहि\",\"बही\",\"बहुत\",\"बाद\",\"बाला\",\"बिलकुल\",\"भि\",\"भितर\",\"भी\",\"भीतर\",\"मगर\",\"मानो\",\"मे\",\"में\",\"यदि\",\"यह\",\"यहाँ\",\"यहां\",\"यहि\",\"यही\",\"या\",\"यिह\",\"ये\",\"रखें\",\"रवासा\",\"रहा\",\"रहे\",\"ऱ्वासा\",\"लिए\",\"लिये\",\"लेकिन\",\"व\",\"वगेरह\",\"वरग\",\"वर्ग\",\"वह\",\"वहाँ\",\"वहां\",\"वहिं\",\"वहीं\",\"वाले\",\"वुह\",\"वे\",\"वग़ैरह\",\"संग\",\"सकता\",\"सकते\",\"सबसे\",\"सभि\",\"सभी\",\"साथ\",\"साबुत\",\"साभ\",\"सारा\",\"से\",\"सो\",\"हि\",\"ही\",\"हुअ\",\"हुआ\",\"हुइ\",\"हुई\",\"हुए\",\"हे\",\"हें\",\"है\",\"हैं\",\"हो\",\"होता\",\"होति\",\"होती\",\"होते\",\"होना\",\"होने\"]\n",
        "stop_words = set(sw)\n",
        "stop_word_parameter=list(sw)\n",
        "stop_word_parameter_eng=list(stopwords.words('english'))\n",
        "final_stop_words=stop_word_parameter+stop_word_parameter_eng\n",
        "final_stop_words"
      ],
      "metadata": {
        "id": "oEyfge_t9him",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9c88c82-78f2-410e-a712-0c9b4a546de6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['अंदर',\n",
              " 'अत',\n",
              " 'अदि',\n",
              " 'अप',\n",
              " 'अपना',\n",
              " 'अपनि',\n",
              " 'अपनी',\n",
              " 'अपने',\n",
              " 'अभि',\n",
              " 'अभी',\n",
              " 'आदि',\n",
              " 'आप',\n",
              " 'इंहिं',\n",
              " 'इंहें',\n",
              " 'इंहों',\n",
              " 'इतयादि',\n",
              " 'इत्यादि',\n",
              " 'इन',\n",
              " 'इनका',\n",
              " 'इन्हीं',\n",
              " 'इन्हें',\n",
              " 'इन्हों',\n",
              " 'इस',\n",
              " 'इसका',\n",
              " 'इसकि',\n",
              " 'इसकी',\n",
              " 'इसके',\n",
              " 'इसमें',\n",
              " 'इसि',\n",
              " 'इसी',\n",
              " 'इसे',\n",
              " 'उंहिं',\n",
              " 'उंहें',\n",
              " 'उंहों',\n",
              " 'उन',\n",
              " 'उनका',\n",
              " 'उनकि',\n",
              " 'उनकी',\n",
              " 'उनके',\n",
              " 'उनको',\n",
              " 'उन्हीं',\n",
              " 'उन्हें',\n",
              " 'उन्हों',\n",
              " 'उस',\n",
              " 'उसके',\n",
              " 'उसि',\n",
              " 'उसी',\n",
              " 'उसे',\n",
              " 'एक',\n",
              " 'एवं',\n",
              " 'एस',\n",
              " 'एसे',\n",
              " 'ऐसे',\n",
              " 'ओर',\n",
              " 'और',\n",
              " 'कइ',\n",
              " 'कई',\n",
              " 'कर',\n",
              " 'करता',\n",
              " 'करते',\n",
              " 'करना',\n",
              " 'करने',\n",
              " 'करें',\n",
              " 'कहते',\n",
              " 'कहा',\n",
              " 'का',\n",
              " 'काफि',\n",
              " 'काफ़ी',\n",
              " 'कि',\n",
              " 'किंहें',\n",
              " 'किंहों',\n",
              " 'कितना',\n",
              " 'किन्हें',\n",
              " 'किन्हों',\n",
              " 'किया',\n",
              " 'किर',\n",
              " 'किस',\n",
              " 'किसि',\n",
              " 'किसी',\n",
              " 'किसे',\n",
              " 'की',\n",
              " 'कुछ',\n",
              " 'कुल',\n",
              " 'के',\n",
              " 'को',\n",
              " 'कोइ',\n",
              " 'कोई',\n",
              " 'कोन',\n",
              " 'कोनसा',\n",
              " 'कौन',\n",
              " 'कौनसा',\n",
              " 'गया',\n",
              " 'घर',\n",
              " 'जब',\n",
              " 'जहाँ',\n",
              " 'जहां',\n",
              " 'जा',\n",
              " 'जिंहें',\n",
              " 'जिंहों',\n",
              " 'जितना',\n",
              " 'जिधर',\n",
              " 'जिन',\n",
              " 'जिन्हें',\n",
              " 'जिन्हों',\n",
              " 'जिस',\n",
              " 'जिसे',\n",
              " 'जीधर',\n",
              " 'जेसा',\n",
              " 'जेसे',\n",
              " 'जैसा',\n",
              " 'जैसे',\n",
              " 'जो',\n",
              " 'तक',\n",
              " 'तब',\n",
              " 'तरह',\n",
              " 'तिंहें',\n",
              " 'तिंहों',\n",
              " 'तिन',\n",
              " 'तिन्हें',\n",
              " 'तिन्हों',\n",
              " 'तिस',\n",
              " 'तिसे',\n",
              " 'तो',\n",
              " 'था',\n",
              " 'थि',\n",
              " 'थी',\n",
              " 'थे',\n",
              " 'दबारा',\n",
              " 'दवारा',\n",
              " 'दिया',\n",
              " 'दुसरा',\n",
              " 'दुसरे',\n",
              " 'दूसरे',\n",
              " 'दो',\n",
              " 'द्वारा',\n",
              " 'न',\n",
              " 'नहिं',\n",
              " 'नहीं',\n",
              " 'ना',\n",
              " 'निचे',\n",
              " 'निहायत',\n",
              " 'नीचे',\n",
              " 'ने',\n",
              " 'पर',\n",
              " 'पहले',\n",
              " 'पुरा',\n",
              " 'पूरा',\n",
              " 'पे',\n",
              " 'फिर',\n",
              " 'बनि',\n",
              " 'बनी',\n",
              " 'बहि',\n",
              " 'बही',\n",
              " 'बहुत',\n",
              " 'बाद',\n",
              " 'बाला',\n",
              " 'बिलकुल',\n",
              " 'भि',\n",
              " 'भितर',\n",
              " 'भी',\n",
              " 'भीतर',\n",
              " 'मगर',\n",
              " 'मानो',\n",
              " 'मे',\n",
              " 'में',\n",
              " 'यदि',\n",
              " 'यह',\n",
              " 'यहाँ',\n",
              " 'यहां',\n",
              " 'यहि',\n",
              " 'यही',\n",
              " 'या',\n",
              " 'यिह',\n",
              " 'ये',\n",
              " 'रखें',\n",
              " 'रवासा',\n",
              " 'रहा',\n",
              " 'रहे',\n",
              " 'ऱ्वासा',\n",
              " 'लिए',\n",
              " 'लिये',\n",
              " 'लेकिन',\n",
              " 'व',\n",
              " 'वगेरह',\n",
              " 'वरग',\n",
              " 'वर्ग',\n",
              " 'वह',\n",
              " 'वहाँ',\n",
              " 'वहां',\n",
              " 'वहिं',\n",
              " 'वहीं',\n",
              " 'वाले',\n",
              " 'वुह',\n",
              " 'वे',\n",
              " 'वग़ैरह',\n",
              " 'संग',\n",
              " 'सकता',\n",
              " 'सकते',\n",
              " 'सबसे',\n",
              " 'सभि',\n",
              " 'सभी',\n",
              " 'साथ',\n",
              " 'साबुत',\n",
              " 'साभ',\n",
              " 'सारा',\n",
              " 'से',\n",
              " 'सो',\n",
              " 'हि',\n",
              " 'ही',\n",
              " 'हुअ',\n",
              " 'हुआ',\n",
              " 'हुइ',\n",
              " 'हुई',\n",
              " 'हुए',\n",
              " 'हे',\n",
              " 'हें',\n",
              " 'है',\n",
              " 'हैं',\n",
              " 'हो',\n",
              " 'होता',\n",
              " 'होति',\n",
              " 'होती',\n",
              " 'होते',\n",
              " 'होना',\n",
              " 'होने',\n",
              " 'i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentence_without_stopwords'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (final_stop_words)]))\n"
      ],
      "metadata": {
        "id": "ygkdalES9h3J"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_lstm = df\n",
        "df.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "qRWIu0JB9j48",
        "outputId": "216a87e2-36c9-4f6d-f286-4b9fbbf185fb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    label                                               text  totalwords  \\\n",
              "0       0                      भीड़ में  बहुत  हब्सी मिलेंगे           5   \n",
              "1       0          साले बेवकूफ अपनी मां मक्खियां  तो हटा दें           8   \n",
              "2       0                   बुर देदो तो मुह में लंड ले लो तो           9   \n",
              "3       0               कुत्ता वहा है चिल्ला तू क्यों रहा है           8   \n",
              "4       1          चाय नहीं पीता हूं मैं इसी को छोड़ दिया ok          10   \n",
              "5       0  बैंकों से सरकार का रिश्ता दलाली का है बड़े बड़...          28   \n",
              "6       0  #पगली  हम तो #बहोत  _शोकीन हैं  #तुजे डोली मे ...          30   \n",
              "7       0  ohh my god  यहां इतने सारे चमचे इसका मतलब जलनख...          14   \n",
              "8       1        आप मेरे कमेंट का इतना  इंतजार क्यों करते है           9   \n",
              "9       0                              भोसड़ी को बात करने दो           5   \n",
              "10      1                              आप बहुत प्यारे हो सनम           5   \n",
              "11      0  हमें   परमात्मा की   भक्ति   करनी    चाहिए   न...          13   \n",
              "12      0                      ये बीजेपी वाले बहुत चूतिया है           6   \n",
              "13      1  तुम्हारे पीछे पड़े हैं  बहुत सारे नमूने हैं   ...          16   \n",
              "14      0                                तेरि माँ किचुत सालि           4   \n",
              "15      1                           सुपर वेरी गुड काला चश्मा           5   \n",
              "16      0  सूचियां इतनी सेक्सी हैं चूत कितनी मस्त होगी तु...           9   \n",
              "17      1                           सुंदर दिसतेस तू नाद खुळा           5   \n",
              "18      1                 नाक क्लीन हो जाता क्या ऐसा करने से           8   \n",
              "19      0  कोई भी धक्का मुक्की नहीं करेंगा सभी को गाली दे...          31   \n",
              "\n",
              "                           sentence_without_stopwords  \n",
              "0                                  भीड़ हब्सी मिलेंगे  \n",
              "1                    साले बेवकूफ मां मक्खियां हटा दें  \n",
              "2                              बुर देदो मुह लंड ले लो  \n",
              "3                          कुत्ता वहा चिल्ला तू क्यों  \n",
              "4                            चाय पीता हूं मैं छोड़ ok  \n",
              "5   बैंकों सरकार रिश्ता दलाली बड़े बड़े चोरों लोन ...  \n",
              "6   #पगली हम #बहोत _शोकीन #तुजे डोली बिठाके लेके #...  \n",
              "7         ohh god इतने सारे चमचे मतलब जलनखोरो कमी नही  \n",
              "8                        मेरे कमेंट इतना इंतजार क्यों  \n",
              "9                                          भोसड़ी बात  \n",
              "10                                         प्यारे सनम  \n",
              "11  हमें परमात्मा भक्ति करनी चाहिए गधी बनोगी sat s...  \n",
              "12                                      बीजेपी चूतिया  \n",
              "13  तुम्हारे पीछे पड़े सारे नमूने फ्रेंड रिक्वेस्ट...  \n",
              "14                                तेरि माँ किचुत सालि  \n",
              "15                           सुपर वेरी गुड काला चश्मा  \n",
              "16   सूचियां इतनी सेक्सी चूत कितनी मस्त होगी तुम्हारी  \n",
              "17                           सुंदर दिसतेस तू नाद खुळा  \n",
              "18                            नाक क्लीन जाता क्या ऐसा  \n",
              "19  धक्का मुक्की करेंगा गाली देने बराबर मोका मिलेग...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59a299aa-3e68-42e5-86b6-844e7788fc92\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>totalwords</th>\n",
              "      <th>sentence_without_stopwords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>भीड़ में  बहुत  हब्सी मिलेंगे</td>\n",
              "      <td>5</td>\n",
              "      <td>भीड़ हब्सी मिलेंगे</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>साले बेवकूफ अपनी मां मक्खियां  तो हटा दें</td>\n",
              "      <td>8</td>\n",
              "      <td>साले बेवकूफ मां मक्खियां हटा दें</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>बुर देदो तो मुह में लंड ले लो तो</td>\n",
              "      <td>9</td>\n",
              "      <td>बुर देदो मुह लंड ले लो</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>कुत्ता वहा है चिल्ला तू क्यों रहा है</td>\n",
              "      <td>8</td>\n",
              "      <td>कुत्ता वहा चिल्ला तू क्यों</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>चाय नहीं पीता हूं मैं इसी को छोड़ दिया ok</td>\n",
              "      <td>10</td>\n",
              "      <td>चाय पीता हूं मैं छोड़ ok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>बैंकों से सरकार का रिश्ता दलाली का है बड़े बड़...</td>\n",
              "      <td>28</td>\n",
              "      <td>बैंकों सरकार रिश्ता दलाली बड़े बड़े चोरों लोन ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>#पगली  हम तो #बहोत  _शोकीन हैं  #तुजे डोली मे ...</td>\n",
              "      <td>30</td>\n",
              "      <td>#पगली हम #बहोत _शोकीन #तुजे डोली बिठाके लेके #...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>ohh my god  यहां इतने सारे चमचे इसका मतलब जलनख...</td>\n",
              "      <td>14</td>\n",
              "      <td>ohh god इतने सारे चमचे मतलब जलनखोरो कमी नही</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>आप मेरे कमेंट का इतना  इंतजार क्यों करते है</td>\n",
              "      <td>9</td>\n",
              "      <td>मेरे कमेंट इतना इंतजार क्यों</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>भोसड़ी को बात करने दो</td>\n",
              "      <td>5</td>\n",
              "      <td>भोसड़ी बात</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>आप बहुत प्यारे हो सनम</td>\n",
              "      <td>5</td>\n",
              "      <td>प्यारे सनम</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>हमें   परमात्मा की   भक्ति   करनी    चाहिए   न...</td>\n",
              "      <td>13</td>\n",
              "      <td>हमें परमात्मा भक्ति करनी चाहिए गधी बनोगी sat s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>ये बीजेपी वाले बहुत चूतिया है</td>\n",
              "      <td>6</td>\n",
              "      <td>बीजेपी चूतिया</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>तुम्हारे पीछे पड़े हैं  बहुत सारे नमूने हैं   ...</td>\n",
              "      <td>16</td>\n",
              "      <td>तुम्हारे पीछे पड़े सारे नमूने फ्रेंड रिक्वेस्ट...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>तेरि माँ किचुत सालि</td>\n",
              "      <td>4</td>\n",
              "      <td>तेरि माँ किचुत सालि</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>सुपर वेरी गुड काला चश्मा</td>\n",
              "      <td>5</td>\n",
              "      <td>सुपर वेरी गुड काला चश्मा</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>सूचियां इतनी सेक्सी हैं चूत कितनी मस्त होगी तु...</td>\n",
              "      <td>9</td>\n",
              "      <td>सूचियां इतनी सेक्सी चूत कितनी मस्त होगी तुम्हारी</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>सुंदर दिसतेस तू नाद खुळा</td>\n",
              "      <td>5</td>\n",
              "      <td>सुंदर दिसतेस तू नाद खुळा</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>नाक क्लीन हो जाता क्या ऐसा करने से</td>\n",
              "      <td>8</td>\n",
              "      <td>नाक क्लीन जाता क्या ऐसा</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>कोई भी धक्का मुक्की नहीं करेंगा सभी को गाली दे...</td>\n",
              "      <td>31</td>\n",
              "      <td>धक्का मुक्की करेंगा गाली देने बराबर मोका मिलेग...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59a299aa-3e68-42e5-86b6-844e7788fc92')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-59a299aa-3e68-42e5-86b6-844e7788fc92 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-59a299aa-3e68-42e5-86b6-844e7788fc92');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "RPsbNl5n9lDK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchtext\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "# from inltk.inltk import tokenize\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "RANDOM_SEED = 123\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "VOCABULARY_SIZE = 20000\n",
        "LEARNING_RATE = 0.005\n",
        "BATCH_SIZE = 100\n",
        "NUM_EPOCHS = 30\n",
        "DEVICE = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM = 256\n",
        "NUM_CLASSES = 2"
      ],
      "metadata": {
        "id": "kFeKZEUy9o1G"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from string import punctuation\n",
        "print(punctuation)\n",
        "temp=[]\n",
        "for item in df['sentence_without_stopwords']:\n",
        "  temp.append(item)\n",
        "\n",
        "all_text = ''.join([c+\" \" for c in temp if c not in punctuation])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPz3AeyZ91Bd",
        "outputId": "70bb9dcf-6a50-4211-cc91-1f00600da54a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_text2 = ' '.join(temp)\n",
        "# create a list of words\n",
        "words = all_text2.split()\n",
        "# Count all the words using Counter Method\n",
        "count_words = Counter(words)\n",
        "\n",
        "total_words = len(words)\n",
        "sorted_words = count_words.most_common(total_words)"
      ],
      "metadata": {
        "id": "sS-GUfP293dl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}"
      ],
      "metadata": {
        "id": "fUb1Qo_B94-m"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_int = []\n",
        "for review in temp:\n",
        "    r = [vocab_to_int[w] for w in review.split()]\n",
        "    reviews_int.append(r)\n",
        "print (reviews_int[0:3])\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(df['sentence_without_stopwords'], df['label'], test_size=0.8)\n",
        "valid_x, test_x, valid_y, test_y = train_test_split(test_x,test_y, test_size=0.3)\n",
        "\n",
        "temp_train_x = train_x\n",
        "temp_valid_x = valid_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bdP4Yqo97Fn",
        "outputId": "1d764f52-51ef-4f94-8216-ac84933b1483"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1417, 11701, 1267], [28, 539, 27, 11702, 914, 810], [1031, 3043, 960, 452, 37, 58]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_labels = np.array(df['label'])\n",
        "print(encoded_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vazd3zo98Sc",
        "outputId": "d2a0f721-88d6-4ef1-de09-a84c94ba73bb"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_features(reviews_int, seq_length):\n",
        "    ''' Return features of review_ints, where each review is padded with 0's or truncated to the input seq_length.\n",
        "    '''\n",
        "    features = np.zeros((len(reviews_int), seq_length), dtype = int)\n",
        "    \n",
        "    for i, review in enumerate(reviews_int):\n",
        "        review_len = len(review)\n",
        "        \n",
        "        if review_len <= seq_length:\n",
        "            zeroes = list(np.zeros(seq_length-review_len))\n",
        "            new = zeroes+review\n",
        "        elif review_len > seq_length:\n",
        "            new = review[0:seq_length]\n",
        "        \n",
        "        features[i,:] = np.array(new)\n",
        "    \n",
        "    return features\n",
        "\n",
        "features = pad_features(reviews_int,1)"
      ],
      "metadata": {
        "id": "33hR7aqR994B"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=df['label']\n",
        "X=features\n",
        "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.8)\n",
        "valid_x, test_x, valid_y, test_y = train_test_split(test_x,test_y, test_size=0.3)\n"
      ],
      "metadata": {
        "id": "6Q2ftrtv9_eq"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y.to_numpy()))\n",
        "valid_data = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y.to_numpy()))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y.to_numpy()))\n",
        "# dataloaders\n",
        "# batch_size = 30\n",
        "# make sure to SHUFFLE your data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE,drop_last=True)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=BATCH_SIZE,drop_last=True)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=BATCH_SIZE,drop_last=True)"
      ],
      "metadata": {
        "id": "Cl8LQDmZ-CUW"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = next(dataiter)"
      ],
      "metadata": {
        "id": "RyBwZSiV-Dtp"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# from torch.optim import Adam\n",
        "class SentimentLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        \n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        # linear and sigmoid layers\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.sig = nn.Sigmoid()\n",
        "        \n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "    \n",
        "        # stack up lstm outputs\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "        \n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "        \n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        return hidden"
      ],
      "metadata": {
        "id": "Yp2OFYqR-FRw"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding\n",
        "output_size = 1\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "net = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_agK-wa-Hjg",
        "outputId": "627930ee-ff79-4e9a-c80d-1e1f74793954"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentimentLSTM(\n",
            "  (embedding): Embedding(29119, 400)\n",
            "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr=0.0001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "# training params\n",
        "\n",
        "# NUM_EPOCHS = 4 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
        "\n",
        "counter = 0\n",
        "print_every = 100\n",
        "clip=5 # gradient clipping\n",
        "train_on_gpu=1\n",
        "# move model to GPU, if available\n",
        "if(train_on_gpu):\n",
        "    net.cuda()\n",
        "\n",
        "net.train()\n",
        "# train for some number of epochs\n",
        "for e in range(NUM_EPOCHS):\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(BATCH_SIZE)\n",
        "\n",
        "    # batch loop\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "\n",
        "        if(train_on_gpu):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # zero accumulated gradients\n",
        "        net.zero_grad()\n",
        "\n",
        "        # get the output from the model\n",
        "        inputs = inputs.type(torch.LongTensor)\n",
        "        output, h = net(inputs.to('cuda'), h)\n",
        "\n",
        "        # calculate the loss and perform backprop\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss stats\n",
        "        if counter % print_every == 0:\n",
        "            # Get validation loss\n",
        "            val_h = net.init_hidden(BATCH_SIZE)\n",
        "            val_losses = []\n",
        "            net.eval()\n",
        "            for inputs, labels in valid_loader:\n",
        "\n",
        "                # Creating new variables for the hidden state, otherwise\n",
        "                # we'd backprop through the entire training history\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                if(train_on_gpu):\n",
        "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "                inputs = inputs.type(torch.LongTensor)\n",
        "                output, val_h = net(inputs.to('cuda'), val_h)\n",
        "                val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            net.train()\n",
        "            print(\"Epoch: {}/{}...\".format(e+1, NUM_EPOCHS),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8KvPwOH-I49",
        "outputId": "5132afaf-b19b-4b4d-b5b2-bd76876dde39"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3/30... Step: 100... Loss: 0.685699... Val Loss: 0.685813\n",
            "Epoch: 5/30... Step: 200... Loss: 0.668384... Val Loss: 0.666202\n",
            "Epoch: 8/30... Step: 300... Loss: 0.598764... Val Loss: 0.632499\n",
            "Epoch: 10/30... Step: 400... Loss: 0.549770... Val Loss: 0.627862\n",
            "Epoch: 13/30... Step: 500... Loss: 0.566824... Val Loss: 0.641555\n",
            "Epoch: 15/30... Step: 600... Loss: 0.473795... Val Loss: 0.652364\n",
            "Epoch: 18/30... Step: 700... Loss: 0.504814... Val Loss: 0.664336\n",
            "Epoch: 20/30... Step: 800... Loss: 0.436129... Val Loss: 0.678348\n",
            "Epoch: 23/30... Step: 900... Loss: 0.457284... Val Loss: 0.696318\n",
            "Epoch: 25/30... Step: 1000... Loss: 0.389529... Val Loss: 0.707487\n",
            "Epoch: 28/30... Step: 1100... Loss: 0.366420... Val Loss: 0.727887\n",
            "Epoch: 30/30... Step: 1200... Loss: 0.461142... Val Loss: 0.742785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get test data loss and accuracy\n",
        "\n",
        "test_losses = [] # track loss\n",
        "num_correct = 0\n",
        "\n",
        "# init hidden state\n",
        "h = net.init_hidden(BATCH_SIZE)\n",
        "\n",
        "net.eval()\n",
        "# pred =0\n",
        "# iterate over test data\n",
        "for inputs, labels in test_loader:\n",
        "\n",
        "    # Creating new variables for the hidden state, otherwise\n",
        "    # we'd backprop through the entire training history\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "    \n",
        "    # get predicted outputs\n",
        "    inputs = inputs.type(torch.LongTensor)\n",
        "    output, h = net(inputs.to('cuda'), h)\n",
        "    \n",
        "    # calculate loss\n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "    \n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
        "    print(inputs)\n",
        "    print(pred)\n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "\n",
        "\n",
        "# -- stats! -- ##\n",
        "# avg test loss\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "# accuracy over all test data\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Test accuracy: {:.3f}\".format(test_acc))"
      ],
      "metadata": {
        "id": "S_3bXhea-K2w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a5f0643-7569-46ff-c357-0c50442142bb"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        [ 1287],\n",
            "        [   23],\n",
            "        [    1],\n",
            "        [  436],\n",
            "        [ 7694],\n",
            "        [   61],\n",
            "        [  428],\n",
            "        [   61],\n",
            "        [  406],\n",
            "        [ 6233],\n",
            "        [   43],\n",
            "        [  117],\n",
            "        [   28],\n",
            "        [    4],\n",
            "        [  129],\n",
            "        [  977],\n",
            "        [  317],\n",
            "        [    8],\n",
            "        [ 2926],\n",
            "        [   64],\n",
            "        [   64],\n",
            "        [10098],\n",
            "        [ 1377],\n",
            "        [  309],\n",
            "        [ 1111],\n",
            "        [  306],\n",
            "        [ 4214],\n",
            "        [    1],\n",
            "        [ 1399],\n",
            "        [  240],\n",
            "        [   61],\n",
            "        [   17],\n",
            "        [   47],\n",
            "        [  485],\n",
            "        [19258],\n",
            "        [  139],\n",
            "        [ 1201],\n",
            "        [  397],\n",
            "        [    1],\n",
            "        [  296],\n",
            "        [  137],\n",
            "        [  215],\n",
            "        [ 3665],\n",
            "        [   16],\n",
            "        [ 1010],\n",
            "        [ 1672],\n",
            "        [  910],\n",
            "        [  336],\n",
            "        [   72],\n",
            "        [   44],\n",
            "        [ 5774],\n",
            "        [    7],\n",
            "        [23246],\n",
            "        [11678],\n",
            "        [  255],\n",
            "        [   56],\n",
            "        [ 6622],\n",
            "        [  435],\n",
            "        [  338],\n",
            "        [   49],\n",
            "        [   19],\n",
            "        [  682],\n",
            "        [  163],\n",
            "        [  306],\n",
            "        [ 2759],\n",
            "        [   29],\n",
            "        [   72],\n",
            "        [   82],\n",
            "        [   40]])\n",
            "tensor([0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
            "        1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
            "        0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
            "        0., 1., 0., 0., 0., 1., 1., 0., 0., 1.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[ 4864],\n",
            "        [  875],\n",
            "        [ 2537],\n",
            "        [ 9244],\n",
            "        [  117],\n",
            "        [ 3468],\n",
            "        [ 1575],\n",
            "        [  239],\n",
            "        [   82],\n",
            "        [  430],\n",
            "        [  184],\n",
            "        [  142],\n",
            "        [ 1011],\n",
            "        [  234],\n",
            "        [ 1863],\n",
            "        [ 5147],\n",
            "        [ 6042],\n",
            "        [  114],\n",
            "        [ 9575],\n",
            "        [ 1814],\n",
            "        [24159],\n",
            "        [  212],\n",
            "        [  238],\n",
            "        [26125],\n",
            "        [ 4313],\n",
            "        [  701],\n",
            "        [    5],\n",
            "        [26982],\n",
            "        [  832],\n",
            "        [  745],\n",
            "        [   29],\n",
            "        [   16],\n",
            "        [    8],\n",
            "        [  760],\n",
            "        [   26],\n",
            "        [   34],\n",
            "        [   72],\n",
            "        [15261],\n",
            "        [  117],\n",
            "        [  246],\n",
            "        [    7],\n",
            "        [  959],\n",
            "        [   11],\n",
            "        [ 4712],\n",
            "        [   45],\n",
            "        [ 3578],\n",
            "        [   65],\n",
            "        [23973],\n",
            "        [  410],\n",
            "        [ 1982],\n",
            "        [  129],\n",
            "        [   21],\n",
            "        [   23],\n",
            "        [  759],\n",
            "        [ 2627],\n",
            "        [   13],\n",
            "        [   16],\n",
            "        [ 4885],\n",
            "        [  713],\n",
            "        [   11],\n",
            "        [   19],\n",
            "        [  420],\n",
            "        [  558],\n",
            "        [19955],\n",
            "        [ 3185],\n",
            "        [  103],\n",
            "        [ 4003],\n",
            "        [ 7827],\n",
            "        [ 1507],\n",
            "        [ 1122],\n",
            "        [ 1607],\n",
            "        [  143],\n",
            "        [21952],\n",
            "        [17945],\n",
            "        [ 1164],\n",
            "        [16987],\n",
            "        [ 1429],\n",
            "        [   61],\n",
            "        [  117],\n",
            "        [ 4358],\n",
            "        [   96],\n",
            "        [   29],\n",
            "        [16221],\n",
            "        [ 4301],\n",
            "        [ 5654],\n",
            "        [   81],\n",
            "        [    8],\n",
            "        [  381],\n",
            "        [ 1017],\n",
            "        [  629],\n",
            "        [  137],\n",
            "        [  212],\n",
            "        [    4],\n",
            "        [   27],\n",
            "        [11863],\n",
            "        [23563],\n",
            "        [28903],\n",
            "        [ 1713],\n",
            "        [  588],\n",
            "        [ 3075]])\n",
            "tensor([0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
            "        0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
            "        0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
            "        0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
            "        1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
            "        1., 1., 0., 0., 0., 1., 1., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[ 5108],\n",
            "        [  782],\n",
            "        [   18],\n",
            "        [  847],\n",
            "        [   40],\n",
            "        [  756],\n",
            "        [   16],\n",
            "        [   23],\n",
            "        [28689],\n",
            "        [  117],\n",
            "        [  975],\n",
            "        [ 2014],\n",
            "        [  352],\n",
            "        [11377],\n",
            "        [    0],\n",
            "        [ 9485],\n",
            "        [21664],\n",
            "        [ 4519],\n",
            "        [ 6738],\n",
            "        [14950],\n",
            "        [   28],\n",
            "        [  361],\n",
            "        [ 3317],\n",
            "        [   79],\n",
            "        [  243],\n",
            "        [  391],\n",
            "        [  146],\n",
            "        [18966],\n",
            "        [ 2651],\n",
            "        [ 2227],\n",
            "        [  705],\n",
            "        [   13],\n",
            "        [ 2416],\n",
            "        [   79],\n",
            "        [  356],\n",
            "        [ 5130],\n",
            "        [ 1149],\n",
            "        [  191],\n",
            "        [ 1245],\n",
            "        [   81],\n",
            "        [  628],\n",
            "        [19148],\n",
            "        [   45],\n",
            "        [  245],\n",
            "        [  306],\n",
            "        [   29],\n",
            "        [   67],\n",
            "        [  763],\n",
            "        [22338],\n",
            "        [10243],\n",
            "        [  802],\n",
            "        [  833],\n",
            "        [   94],\n",
            "        [  295],\n",
            "        [  160],\n",
            "        [  787],\n",
            "        [   25],\n",
            "        [ 4354],\n",
            "        [ 2330],\n",
            "        [  237],\n",
            "        [  212],\n",
            "        [  682],\n",
            "        [   60],\n",
            "        [   78],\n",
            "        [  146],\n",
            "        [25620],\n",
            "        [ 1512],\n",
            "        [   16],\n",
            "        [19751],\n",
            "        [  642],\n",
            "        [ 6008],\n",
            "        [    8],\n",
            "        [ 2461],\n",
            "        [   11],\n",
            "        [19814],\n",
            "        [  622],\n",
            "        [10163],\n",
            "        [  254],\n",
            "        [   14],\n",
            "        [  589],\n",
            "        [ 4126],\n",
            "        [  301],\n",
            "        [ 1636],\n",
            "        [ 1377],\n",
            "        [    8],\n",
            "        [ 7556],\n",
            "        [   14],\n",
            "        [ 1210],\n",
            "        [11479],\n",
            "        [   24],\n",
            "        [    8],\n",
            "        [   82],\n",
            "        [   11],\n",
            "        [  368],\n",
            "        [   28],\n",
            "        [   47],\n",
            "        [15892],\n",
            "        [ 2711],\n",
            "        [ 4024],\n",
            "        [  975]])\n",
            "tensor([1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
            "        1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
            "        1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
            "        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
            "        1., 0., 1., 1., 0., 1., 0., 0., 0., 1.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[ 4162],\n",
            "        [   98],\n",
            "        [    1],\n",
            "        [  161],\n",
            "        [ 6044],\n",
            "        [   51],\n",
            "        [    1],\n",
            "        [ 1094],\n",
            "        [  578],\n",
            "        [ 3172],\n",
            "        [  420],\n",
            "        [27320],\n",
            "        [ 2898],\n",
            "        [ 2084],\n",
            "        [  624],\n",
            "        [   41],\n",
            "        [  117],\n",
            "        [   75],\n",
            "        [   96],\n",
            "        [   25],\n",
            "        [ 2956],\n",
            "        [  333],\n",
            "        [   11],\n",
            "        [ 1945],\n",
            "        [  495],\n",
            "        [ 1834],\n",
            "        [ 1541],\n",
            "        [ 4532],\n",
            "        [   26],\n",
            "        [  231],\n",
            "        [  140],\n",
            "        [    4],\n",
            "        [  948],\n",
            "        [  860],\n",
            "        [   24],\n",
            "        [   23],\n",
            "        [  101],\n",
            "        [   49],\n",
            "        [ 1064],\n",
            "        [    1],\n",
            "        [  380],\n",
            "        [  556],\n",
            "        [   15],\n",
            "        [  197],\n",
            "        [   47],\n",
            "        [    8],\n",
            "        [   11],\n",
            "        [   47],\n",
            "        [   56],\n",
            "        [  365],\n",
            "        [   81],\n",
            "        [ 1065],\n",
            "        [  228],\n",
            "        [  543],\n",
            "        [  197],\n",
            "        [ 2970],\n",
            "        [   61],\n",
            "        [ 1892],\n",
            "        [ 2553],\n",
            "        [23921],\n",
            "        [  573],\n",
            "        [   25],\n",
            "        [ 1337],\n",
            "        [  213],\n",
            "        [   27],\n",
            "        [ 1776],\n",
            "        [  724],\n",
            "        [ 1102],\n",
            "        [   14],\n",
            "        [  198],\n",
            "        [ 7189],\n",
            "        [  204],\n",
            "        [  720],\n",
            "        [  134],\n",
            "        [   13],\n",
            "        [  710],\n",
            "        [   84],\n",
            "        [   41],\n",
            "        [ 9039],\n",
            "        [  541],\n",
            "        [   18],\n",
            "        [   74],\n",
            "        [23421],\n",
            "        [ 1309],\n",
            "        [   64],\n",
            "        [ 3300],\n",
            "        [11827],\n",
            "        [   18],\n",
            "        [  117],\n",
            "        [  193],\n",
            "        [   29],\n",
            "        [  528],\n",
            "        [ 2133],\n",
            "        [    1],\n",
            "        [ 1459],\n",
            "        [   63],\n",
            "        [ 2457],\n",
            "        [  153],\n",
            "        [   81],\n",
            "        [   86]])\n",
            "tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
            "        1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
            "        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
            "        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
            "        1., 0., 0., 1., 0., 0., 1., 1., 1., 1.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[17786],\n",
            "        [ 1221],\n",
            "        [12846],\n",
            "        [    8],\n",
            "        [   13],\n",
            "        [  351],\n",
            "        [  191],\n",
            "        [  268],\n",
            "        [   11],\n",
            "        [  101],\n",
            "        [  117],\n",
            "        [  257],\n",
            "        [ 1338],\n",
            "        [   26],\n",
            "        [  293],\n",
            "        [  246],\n",
            "        [   49],\n",
            "        [  184],\n",
            "        [ 4743],\n",
            "        [   33],\n",
            "        [ 4422],\n",
            "        [  862],\n",
            "        [10037],\n",
            "        [ 1827],\n",
            "        [  566],\n",
            "        [  158],\n",
            "        [  306],\n",
            "        [ 1802],\n",
            "        [   22],\n",
            "        [ 4151],\n",
            "        [  310],\n",
            "        [  485],\n",
            "        [  528],\n",
            "        [   22],\n",
            "        [ 1177],\n",
            "        [ 3916],\n",
            "        [   46],\n",
            "        [ 4744],\n",
            "        [  492],\n",
            "        [ 7706],\n",
            "        [   28],\n",
            "        [   13],\n",
            "        [18106],\n",
            "        [  163],\n",
            "        [ 2438],\n",
            "        [  369],\n",
            "        [   47],\n",
            "        [16682],\n",
            "        [    1],\n",
            "        [  172],\n",
            "        [ 7856],\n",
            "        [23986],\n",
            "        [   63],\n",
            "        [ 6538],\n",
            "        [   18],\n",
            "        [ 1027],\n",
            "        [  160],\n",
            "        [   65],\n",
            "        [   89],\n",
            "        [23030],\n",
            "        [   82],\n",
            "        [   49],\n",
            "        [    2],\n",
            "        [   47],\n",
            "        [  102],\n",
            "        [ 1607],\n",
            "        [   16],\n",
            "        [ 9408],\n",
            "        [  104],\n",
            "        [ 2360],\n",
            "        [ 9839],\n",
            "        [  345],\n",
            "        [ 2759],\n",
            "        [  478],\n",
            "        [28725],\n",
            "        [  585],\n",
            "        [   41],\n",
            "        [  166],\n",
            "        [   33],\n",
            "        [  435],\n",
            "        [  151],\n",
            "        [28179],\n",
            "        [15504],\n",
            "        [ 2194],\n",
            "        [ 7618],\n",
            "        [16197],\n",
            "        [  699],\n",
            "        [  618],\n",
            "        [   81],\n",
            "        [  441],\n",
            "        [   40],\n",
            "        [  268],\n",
            "        [  380],\n",
            "        [   75],\n",
            "        [    4],\n",
            "        [   33],\n",
            "        [21148],\n",
            "        [ 1674],\n",
            "        [   31],\n",
            "        [18049]])\n",
            "tensor([0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
            "        1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
            "        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
            "        0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
            "        1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
            "        1., 1., 1., 0., 0., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[  268],\n",
            "        [  108],\n",
            "        [   76],\n",
            "        [  301],\n",
            "        [  812],\n",
            "        [14845],\n",
            "        [  388],\n",
            "        [ 5652],\n",
            "        [   13],\n",
            "        [ 2080],\n",
            "        [  556],\n",
            "        [ 2233],\n",
            "        [ 2651],\n",
            "        [  142],\n",
            "        [ 4174],\n",
            "        [   64],\n",
            "        [17331],\n",
            "        [  274],\n",
            "        [  872],\n",
            "        [  108],\n",
            "        [12897],\n",
            "        [ 1404],\n",
            "        [ 2500],\n",
            "        [27554],\n",
            "        [  264],\n",
            "        [ 1002],\n",
            "        [   43],\n",
            "        [ 4870],\n",
            "        [  448],\n",
            "        [  400],\n",
            "        [ 2501],\n",
            "        [  122],\n",
            "        [  372],\n",
            "        [  609],\n",
            "        [   16],\n",
            "        [  643],\n",
            "        [ 2470],\n",
            "        [ 3190],\n",
            "        [   86],\n",
            "        [ 2485],\n",
            "        [ 2193],\n",
            "        [  249],\n",
            "        [   21],\n",
            "        [20302],\n",
            "        [  212],\n",
            "        [   21],\n",
            "        [ 9402],\n",
            "        [ 1231],\n",
            "        [   61],\n",
            "        [   94],\n",
            "        [ 2854],\n",
            "        [ 4602],\n",
            "        [ 3491],\n",
            "        [    0],\n",
            "        [ 1391],\n",
            "        [ 1730],\n",
            "        [   49],\n",
            "        [  139],\n",
            "        [ 1391],\n",
            "        [    5],\n",
            "        [  243],\n",
            "        [   72],\n",
            "        [  992],\n",
            "        [  927],\n",
            "        [  117],\n",
            "        [  544],\n",
            "        [   47],\n",
            "        [    5],\n",
            "        [ 3907],\n",
            "        [ 5938],\n",
            "        [   18],\n",
            "        [  129],\n",
            "        [  959],\n",
            "        [    8],\n",
            "        [    7],\n",
            "        [ 8923],\n",
            "        [  498],\n",
            "        [  191],\n",
            "        [   24],\n",
            "        [  991],\n",
            "        [  701],\n",
            "        [    5],\n",
            "        [   86],\n",
            "        [  526],\n",
            "        [   94],\n",
            "        [ 6017],\n",
            "        [  987],\n",
            "        [ 1158],\n",
            "        [  214],\n",
            "        [  135],\n",
            "        [ 2152],\n",
            "        [  197],\n",
            "        [    5],\n",
            "        [  237],\n",
            "        [ 4290],\n",
            "        [   88],\n",
            "        [ 4729],\n",
            "        [   82],\n",
            "        [ 9166],\n",
            "        [  414]])\n",
            "tensor([1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
            "        1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
            "        0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
            "        1., 1., 0., 0., 1., 1., 1., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[ 1417],\n",
            "        [ 9255],\n",
            "        [  242],\n",
            "        [   16],\n",
            "        [   22],\n",
            "        [  281],\n",
            "        [   78],\n",
            "        [  789],\n",
            "        [  670],\n",
            "        [   47],\n",
            "        [ 2046],\n",
            "        [  868],\n",
            "        [  299],\n",
            "        [26547],\n",
            "        [   24],\n",
            "        [24758],\n",
            "        [22519],\n",
            "        [    8],\n",
            "        [ 2553],\n",
            "        [ 2897],\n",
            "        [  573],\n",
            "        [10262],\n",
            "        [   64],\n",
            "        [  254],\n",
            "        [   60],\n",
            "        [  205],\n",
            "        [ 1391],\n",
            "        [25989],\n",
            "        [  277],\n",
            "        [20261],\n",
            "        [ 4656],\n",
            "        [ 3132],\n",
            "        [ 7048],\n",
            "        [ 2148],\n",
            "        [   68],\n",
            "        [ 1031],\n",
            "        [  165],\n",
            "        [ 7453],\n",
            "        [   35],\n",
            "        [  966],\n",
            "        [   25],\n",
            "        [  460],\n",
            "        [ 3394],\n",
            "        [  117],\n",
            "        [  610],\n",
            "        [ 2421],\n",
            "        [   29],\n",
            "        [ 1927],\n",
            "        [   13],\n",
            "        [   82],\n",
            "        [ 1016],\n",
            "        [  143],\n",
            "        [  288],\n",
            "        [   24],\n",
            "        [   14],\n",
            "        [  430],\n",
            "        [  422],\n",
            "        [16358],\n",
            "        [ 1243],\n",
            "        [23121],\n",
            "        [ 7310],\n",
            "        [ 5566],\n",
            "        [   81],\n",
            "        [  545],\n",
            "        [   40],\n",
            "        [   28],\n",
            "        [ 1121],\n",
            "        [  633],\n",
            "        [13860],\n",
            "        [ 1031],\n",
            "        [24515],\n",
            "        [17260],\n",
            "        [   75],\n",
            "        [  126],\n",
            "        [   18],\n",
            "        [15596],\n",
            "        [ 7094],\n",
            "        [  464],\n",
            "        [  201],\n",
            "        [16341],\n",
            "        [   67],\n",
            "        [   96],\n",
            "        [   77],\n",
            "        [  146],\n",
            "        [ 3753],\n",
            "        [ 1271],\n",
            "        [ 7629],\n",
            "        [  955],\n",
            "        [   18],\n",
            "        [24655],\n",
            "        [  191],\n",
            "        [   61],\n",
            "        [ 1559],\n",
            "        [   96],\n",
            "        [  274],\n",
            "        [ 1191],\n",
            "        [ 4796],\n",
            "        [ 4743],\n",
            "        [  697],\n",
            "        [  251]])\n",
            "tensor([1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
            "        0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
            "        1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
            "        1., 0., 0., 0., 1., 1., 0., 1., 1., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[  137],\n",
            "        [ 4081],\n",
            "        [   57],\n",
            "        [  299],\n",
            "        [ 2194],\n",
            "        [26985],\n",
            "        [   26],\n",
            "        [   82],\n",
            "        [   78],\n",
            "        [19119],\n",
            "        [  542],\n",
            "        [ 7972],\n",
            "        [   16],\n",
            "        [ 2825],\n",
            "        [  496],\n",
            "        [ 5109],\n",
            "        [  617],\n",
            "        [   96],\n",
            "        [ 1828],\n",
            "        [27489],\n",
            "        [   38],\n",
            "        [ 7941],\n",
            "        [ 1607],\n",
            "        [ 5848],\n",
            "        [   61],\n",
            "        [ 3859],\n",
            "        [   79],\n",
            "        [ 1852],\n",
            "        [   81],\n",
            "        [  375],\n",
            "        [   45],\n",
            "        [  945],\n",
            "        [ 2778],\n",
            "        [  323],\n",
            "        [  279],\n",
            "        [24478],\n",
            "        [  841],\n",
            "        [  579],\n",
            "        [  616],\n",
            "        [ 4880],\n",
            "        [ 7206],\n",
            "        [  573],\n",
            "        [ 2067],\n",
            "        [  441],\n",
            "        [  345],\n",
            "        [  400],\n",
            "        [ 6739],\n",
            "        [ 1583],\n",
            "        [    5],\n",
            "        [ 4214],\n",
            "        [  168],\n",
            "        [   43],\n",
            "        [ 1618],\n",
            "        [  191],\n",
            "        [  739],\n",
            "        [   41],\n",
            "        [ 5243],\n",
            "        [  174],\n",
            "        [ 1776],\n",
            "        [   14],\n",
            "        [   63],\n",
            "        [  915],\n",
            "        [   18],\n",
            "        [ 2515],\n",
            "        [   40],\n",
            "        [19921],\n",
            "        [  125],\n",
            "        [ 1116],\n",
            "        [  142],\n",
            "        [    8],\n",
            "        [ 1035],\n",
            "        [11895],\n",
            "        [   61],\n",
            "        [  245],\n",
            "        [  215],\n",
            "        [ 3044],\n",
            "        [   13],\n",
            "        [  119],\n",
            "        [  669],\n",
            "        [  422],\n",
            "        [  923],\n",
            "        [  524],\n",
            "        [    9],\n",
            "        [   40],\n",
            "        [ 3902],\n",
            "        [  309],\n",
            "        [10275],\n",
            "        [  212],\n",
            "        [   31],\n",
            "        [ 1397],\n",
            "        [   41],\n",
            "        [   14],\n",
            "        [  277],\n",
            "        [ 3396],\n",
            "        [   31],\n",
            "        [   25],\n",
            "        [   81],\n",
            "        [   35],\n",
            "        [26671],\n",
            "        [  117]])\n",
            "tensor([1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
            "        0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
            "        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
            "        0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
            "        0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
            "        0., 1., 1., 0., 0., 1., 1., 0., 1., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[  270],\n",
            "        [ 3850],\n",
            "        [ 3549],\n",
            "        [   11],\n",
            "        [ 1022],\n",
            "        [ 1348],\n",
            "        [  146],\n",
            "        [ 8986],\n",
            "        [26864],\n",
            "        [ 1272],\n",
            "        [    8],\n",
            "        [ 5360],\n",
            "        [  114],\n",
            "        [   25],\n",
            "        [  122],\n",
            "        [   81],\n",
            "        [  374],\n",
            "        [  157],\n",
            "        [19572],\n",
            "        [   61],\n",
            "        [  529],\n",
            "        [  388],\n",
            "        [28393],\n",
            "        [   49],\n",
            "        [   10],\n",
            "        [   25],\n",
            "        [ 1800],\n",
            "        [  104],\n",
            "        [ 8521],\n",
            "        [  104],\n",
            "        [   19],\n",
            "        [   61],\n",
            "        [  184],\n",
            "        [  418],\n",
            "        [ 6344],\n",
            "        [20540],\n",
            "        [  305],\n",
            "        [ 1027],\n",
            "        [  274],\n",
            "        [24970],\n",
            "        [   77],\n",
            "        [ 4112],\n",
            "        [11398],\n",
            "        [   64],\n",
            "        [  286],\n",
            "        [  799],\n",
            "        [  219],\n",
            "        [   46],\n",
            "        [ 1638],\n",
            "        [   15],\n",
            "        [23671],\n",
            "        [  148],\n",
            "        [ 2739],\n",
            "        [  180],\n",
            "        [ 1271],\n",
            "        [   29],\n",
            "        [26299],\n",
            "        [   13],\n",
            "        [18782],\n",
            "        [   25],\n",
            "        [  279],\n",
            "        [   43],\n",
            "        [  448],\n",
            "        [    5],\n",
            "        [28774],\n",
            "        [23815],\n",
            "        [  546],\n",
            "        [  860],\n",
            "        [   81],\n",
            "        [  438],\n",
            "        [   49],\n",
            "        [    8],\n",
            "        [  948],\n",
            "        [  163],\n",
            "        [   58],\n",
            "        [20916],\n",
            "        [   16],\n",
            "        [   99],\n",
            "        [ 4041],\n",
            "        [   35],\n",
            "        [   24],\n",
            "        [  274],\n",
            "        [  329],\n",
            "        [  317],\n",
            "        [ 1246],\n",
            "        [  162],\n",
            "        [15963],\n",
            "        [ 7219],\n",
            "        [ 2778],\n",
            "        [ 1016],\n",
            "        [ 1033],\n",
            "        [   11],\n",
            "        [ 2859],\n",
            "        [  519],\n",
            "        [ 1540],\n",
            "        [  285],\n",
            "        [   96],\n",
            "        [  633],\n",
            "        [ 9487],\n",
            "        [   22]])\n",
            "tensor([0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
            "        0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
            "        0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
            "        0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
            "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[  659],\n",
            "        [11111],\n",
            "        [  134],\n",
            "        [   49],\n",
            "        [ 5614],\n",
            "        [18981],\n",
            "        [   72],\n",
            "        [  352],\n",
            "        [ 5054],\n",
            "        [24815],\n",
            "        [ 1132],\n",
            "        [   16],\n",
            "        [  733],\n",
            "        [   25],\n",
            "        [ 3080],\n",
            "        [    5],\n",
            "        [   43],\n",
            "        [ 7038],\n",
            "        [  591],\n",
            "        [  748],\n",
            "        [  241],\n",
            "        [   92],\n",
            "        [  278],\n",
            "        [ 2665],\n",
            "        [ 1178],\n",
            "        [   43],\n",
            "        [  252],\n",
            "        [ 1329],\n",
            "        [ 1282],\n",
            "        [   77],\n",
            "        [ 5457],\n",
            "        [  237],\n",
            "        [   45],\n",
            "        [  563],\n",
            "        [  356],\n",
            "        [    7],\n",
            "        [    7],\n",
            "        [    9],\n",
            "        [  425],\n",
            "        [   64],\n",
            "        [   47],\n",
            "        [29070],\n",
            "        [23058],\n",
            "        [   13],\n",
            "        [  717],\n",
            "        [  142],\n",
            "        [ 1512],\n",
            "        [  317],\n",
            "        [   87],\n",
            "        [  498],\n",
            "        [  146],\n",
            "        [19509],\n",
            "        [   13],\n",
            "        [   26],\n",
            "        [  669],\n",
            "        [   28],\n",
            "        [ 3104],\n",
            "        [  477],\n",
            "        [  279],\n",
            "        [  161],\n",
            "        [  260],\n",
            "        [  260],\n",
            "        [   23],\n",
            "        [ 1788],\n",
            "        [22193],\n",
            "        [20050],\n",
            "        [  225],\n",
            "        [    8],\n",
            "        [13078],\n",
            "        [   11],\n",
            "        [14280],\n",
            "        [    7],\n",
            "        [   10],\n",
            "        [   89],\n",
            "        [23721],\n",
            "        [   28],\n",
            "        [  679],\n",
            "        [  991],\n",
            "        [ 3118],\n",
            "        [   31],\n",
            "        [ 2543],\n",
            "        [   35],\n",
            "        [  724],\n",
            "        [ 5198],\n",
            "        [   16],\n",
            "        [  383],\n",
            "        [  281],\n",
            "        [    8],\n",
            "        [ 1368],\n",
            "        [   40],\n",
            "        [  953],\n",
            "        [ 1626],\n",
            "        [  862],\n",
            "        [ 7805],\n",
            "        [ 3050],\n",
            "        [ 1124],\n",
            "        [   13],\n",
            "        [   87],\n",
            "        [ 1795],\n",
            "        [  429]])\n",
            "tensor([1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
            "        1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
            "        0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0.,\n",
            "        1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1.,\n",
            "        0., 0., 1., 0., 1., 0., 1., 1., 1., 1.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[ 9514],\n",
            "        [ 2502],\n",
            "        [ 4797],\n",
            "        [  179],\n",
            "        [ 6150],\n",
            "        [    9],\n",
            "        [ 1269],\n",
            "        [   87],\n",
            "        [ 2565],\n",
            "        [  519],\n",
            "        [   54],\n",
            "        [   40],\n",
            "        [  621],\n",
            "        [12258],\n",
            "        [ 1061],\n",
            "        [  129],\n",
            "        [  116],\n",
            "        [   34],\n",
            "        [   33],\n",
            "        [    7],\n",
            "        [  699],\n",
            "        [   29],\n",
            "        [  112],\n",
            "        [   65],\n",
            "        [ 3241],\n",
            "        [13007],\n",
            "        [ 1658],\n",
            "        [ 1464],\n",
            "        [  175],\n",
            "        [  179],\n",
            "        [  365],\n",
            "        [  104],\n",
            "        [    1],\n",
            "        [  151],\n",
            "        [  517],\n",
            "        [ 1202],\n",
            "        [ 6613],\n",
            "        [ 1168],\n",
            "        [  337],\n",
            "        [  679],\n",
            "        [  344],\n",
            "        [ 1073],\n",
            "        [ 1102],\n",
            "        [ 3358],\n",
            "        [   24],\n",
            "        [   99],\n",
            "        [ 2097],\n",
            "        [ 7143],\n",
            "        [   29],\n",
            "        [ 4283],\n",
            "        [27908],\n",
            "        [25374],\n",
            "        [ 4358],\n",
            "        [21852],\n",
            "        [ 1619],\n",
            "        [   25],\n",
            "        [ 1966],\n",
            "        [  130],\n",
            "        [    2],\n",
            "        [  215],\n",
            "        [16383],\n",
            "        [  473],\n",
            "        [ 1005],\n",
            "        [ 3510],\n",
            "        [  114],\n",
            "        [  174],\n",
            "        [ 1182],\n",
            "        [ 1112],\n",
            "        [   65],\n",
            "        [   40],\n",
            "        [   82],\n",
            "        [    8],\n",
            "        [ 4805],\n",
            "        [ 6935],\n",
            "        [ 1051],\n",
            "        [10149],\n",
            "        [14195],\n",
            "        [   47],\n",
            "        [   31],\n",
            "        [  713],\n",
            "        [ 3039],\n",
            "        [ 3960],\n",
            "        [ 2464],\n",
            "        [ 1871],\n",
            "        [  919],\n",
            "        [ 4396],\n",
            "        [   35],\n",
            "        [  270],\n",
            "        [ 3730],\n",
            "        [  192],\n",
            "        [    8],\n",
            "        [   49],\n",
            "        [ 3939],\n",
            "        [  225],\n",
            "        [ 1824],\n",
            "        [  970],\n",
            "        [  243],\n",
            "        [  122],\n",
            "        [  786],\n",
            "        [   31]])\n",
            "tensor([1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
            "        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
            "        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
            "        1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
            "        1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
            "        1., 0., 0., 0., 1., 1., 0., 0., 1., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[   40],\n",
            "        [ 1889],\n",
            "        [ 2148],\n",
            "        [    7],\n",
            "        [   26],\n",
            "        [   29],\n",
            "        [  356],\n",
            "        [   47],\n",
            "        [   14],\n",
            "        [  714],\n",
            "        [   61],\n",
            "        [   25],\n",
            "        [23355],\n",
            "        [  580],\n",
            "        [  111],\n",
            "        [   56],\n",
            "        [   98],\n",
            "        [ 1016],\n",
            "        [  676],\n",
            "        [  452],\n",
            "        [    7],\n",
            "        [11094],\n",
            "        [  299],\n",
            "        [24901],\n",
            "        [  114],\n",
            "        [  117],\n",
            "        [    5],\n",
            "        [    1],\n",
            "        [  716],\n",
            "        [   11],\n",
            "        [  142],\n",
            "        [  966],\n",
            "        [  134],\n",
            "        [  679],\n",
            "        [ 1222],\n",
            "        [  794],\n",
            "        [ 7947],\n",
            "        [   21],\n",
            "        [   18],\n",
            "        [  296],\n",
            "        [    1],\n",
            "        [  309],\n",
            "        [  483],\n",
            "        [ 5835],\n",
            "        [    8],\n",
            "        [ 1730],\n",
            "        [   57],\n",
            "        [ 1573],\n",
            "        [   25],\n",
            "        [26931],\n",
            "        [ 7053],\n",
            "        [ 3747],\n",
            "        [   87],\n",
            "        [  618],\n",
            "        [    8],\n",
            "        [   72],\n",
            "        [   16],\n",
            "        [  391],\n",
            "        [   46],\n",
            "        [ 2491],\n",
            "        [ 2331],\n",
            "        [    1],\n",
            "        [  112],\n",
            "        [    8],\n",
            "        [ 1625],\n",
            "        [   41],\n",
            "        [23236],\n",
            "        [   73],\n",
            "        [   29],\n",
            "        [27357],\n",
            "        [  370],\n",
            "        [ 1592],\n",
            "        [   49],\n",
            "        [ 5242],\n",
            "        [  180],\n",
            "        [ 3645],\n",
            "        [    1],\n",
            "        [ 1544],\n",
            "        [   16],\n",
            "        [  490],\n",
            "        [   13],\n",
            "        [  261],\n",
            "        [  701],\n",
            "        [  369],\n",
            "        [ 4048],\n",
            "        [  750],\n",
            "        [  285],\n",
            "        [    4],\n",
            "        [ 1186],\n",
            "        [   87],\n",
            "        [  485],\n",
            "        [    8],\n",
            "        [ 2201],\n",
            "        [ 1125],\n",
            "        [ 1390],\n",
            "        [ 4951],\n",
            "        [  457],\n",
            "        [ 2959],\n",
            "        [   57],\n",
            "        [12023]])\n",
            "tensor([1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
            "        1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
            "        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
            "        1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
            "        0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
            "        0., 1., 0., 0., 1., 1., 0., 0., 1., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[   22],\n",
            "        [ 3864],\n",
            "        [  772],\n",
            "        [   60],\n",
            "        [  129],\n",
            "        [13595],\n",
            "        [   30],\n",
            "        [ 3058],\n",
            "        [   25],\n",
            "        [   54],\n",
            "        [  117],\n",
            "        [  626],\n",
            "        [    8],\n",
            "        [ 1121],\n",
            "        [   44],\n",
            "        [21374],\n",
            "        [   28],\n",
            "        [   89],\n",
            "        [   47],\n",
            "        [ 6528],\n",
            "        [ 7227],\n",
            "        [   21],\n",
            "        [27848],\n",
            "        [  110],\n",
            "        [ 6938],\n",
            "        [  138],\n",
            "        [    8],\n",
            "        [   30],\n",
            "        [   68],\n",
            "        [   43],\n",
            "        [  141],\n",
            "        [ 1736],\n",
            "        [ 1404],\n",
            "        [  117],\n",
            "        [17354],\n",
            "        [ 1636],\n",
            "        [  420],\n",
            "        [   82],\n",
            "        [ 4989],\n",
            "        [18073],\n",
            "        [  423],\n",
            "        [  119],\n",
            "        [   25],\n",
            "        [  659],\n",
            "        [  804],\n",
            "        [  336],\n",
            "        [  322],\n",
            "        [  293],\n",
            "        [ 1875],\n",
            "        [ 1337],\n",
            "        [ 2031],\n",
            "        [   10],\n",
            "        [ 5569],\n",
            "        [    5],\n",
            "        [    5],\n",
            "        [  307],\n",
            "        [17725],\n",
            "        [   28],\n",
            "        [ 2881],\n",
            "        [   60],\n",
            "        [    1],\n",
            "        [  168],\n",
            "        [  478],\n",
            "        [  823],\n",
            "        [   49],\n",
            "        [    2],\n",
            "        [ 2956],\n",
            "        [  117],\n",
            "        [  307],\n",
            "        [   84],\n",
            "        [   61],\n",
            "        [ 1776],\n",
            "        [ 1975],\n",
            "        [25561],\n",
            "        [ 1159],\n",
            "        [   84],\n",
            "        [ 1016],\n",
            "        [  562],\n",
            "        [  857],\n",
            "        [ 8339],\n",
            "        [   87],\n",
            "        [   14],\n",
            "        [  285],\n",
            "        [  179],\n",
            "        [   49],\n",
            "        [ 7213],\n",
            "        [   35],\n",
            "        [  180],\n",
            "        [ 3547],\n",
            "        [   79],\n",
            "        [10937],\n",
            "        [   36],\n",
            "        [  126],\n",
            "        [ 1215],\n",
            "        [  259],\n",
            "        [   28],\n",
            "        [ 1404],\n",
            "        [  314],\n",
            "        [ 5449],\n",
            "        [  180]])\n",
            "tensor([0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
            "        1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
            "        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 1., 0., 0., 1.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[17171],\n",
            "        [  152],\n",
            "        [  898],\n",
            "        [  166],\n",
            "        [27549],\n",
            "        [ 1380],\n",
            "        [ 4385],\n",
            "        [ 2201],\n",
            "        [ 1028],\n",
            "        [  883],\n",
            "        [   28],\n",
            "        [20067],\n",
            "        [  179],\n",
            "        [  312],\n",
            "        [  492],\n",
            "        [  443],\n",
            "        [23254],\n",
            "        [   82],\n",
            "        [   83],\n",
            "        [ 1378],\n",
            "        [  117],\n",
            "        [ 3165],\n",
            "        [   14],\n",
            "        [22857],\n",
            "        [   16],\n",
            "        [  134],\n",
            "        [  493],\n",
            "        [   24],\n",
            "        [  214],\n",
            "        [15080],\n",
            "        [   35],\n",
            "        [   98],\n",
            "        [ 5406],\n",
            "        [ 2260],\n",
            "        [ 2925],\n",
            "        [ 1264],\n",
            "        [ 1289],\n",
            "        [14359],\n",
            "        [20640],\n",
            "        [16903],\n",
            "        [  391],\n",
            "        [  134],\n",
            "        [   82],\n",
            "        [ 3208],\n",
            "        [   11],\n",
            "        [   16],\n",
            "        [   40],\n",
            "        [15578],\n",
            "        [ 2363],\n",
            "        [  285],\n",
            "        [ 2033],\n",
            "        [   44],\n",
            "        [  162],\n",
            "        [ 1265],\n",
            "        [   78],\n",
            "        [ 1201],\n",
            "        [  716],\n",
            "        [    1],\n",
            "        [19926],\n",
            "        [  385],\n",
            "        [ 4640],\n",
            "        [   81],\n",
            "        [ 1575],\n",
            "        [  143],\n",
            "        [  362],\n",
            "        [  178],\n",
            "        [ 1404],\n",
            "        [18876],\n",
            "        [ 9097],\n",
            "        [    5],\n",
            "        [   45],\n",
            "        [ 1322],\n",
            "        [   23],\n",
            "        [    9],\n",
            "        [  329],\n",
            "        [26605],\n",
            "        [   86],\n",
            "        [   45],\n",
            "        [  462],\n",
            "        [ 2113],\n",
            "        [ 1829],\n",
            "        [ 1210],\n",
            "        [   28],\n",
            "        [   61],\n",
            "        [   82],\n",
            "        [25421],\n",
            "        [  628],\n",
            "        [   61],\n",
            "        [  748],\n",
            "        [  146],\n",
            "        [ 2566],\n",
            "        [ 1424],\n",
            "        [ 4358],\n",
            "        [ 5889],\n",
            "        [  117],\n",
            "        [22353],\n",
            "        [    1],\n",
            "        [ 3102],\n",
            "        [  104],\n",
            "        [  146]])\n",
            "tensor([1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
            "        0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
            "        0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
            "        1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
            "        1., 0., 1., 1., 0., 1., 1., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[   56],\n",
            "        [ 4956],\n",
            "        [  429],\n",
            "        [ 3516],\n",
            "        [  283],\n",
            "        [ 7055],\n",
            "        [13061],\n",
            "        [ 4317],\n",
            "        [   60],\n",
            "        [  273],\n",
            "        [  654],\n",
            "        [24123],\n",
            "        [   75],\n",
            "        [18804],\n",
            "        [ 3450],\n",
            "        [ 1987],\n",
            "        [ 4399],\n",
            "        [  792],\n",
            "        [  527],\n",
            "        [   18],\n",
            "        [    2],\n",
            "        [  114],\n",
            "        [    1],\n",
            "        [  281],\n",
            "        [  268],\n",
            "        [   72],\n",
            "        [  936],\n",
            "        [ 2651],\n",
            "        [   18],\n",
            "        [  174],\n",
            "        [   25],\n",
            "        [   16],\n",
            "        [  992],\n",
            "        [19850],\n",
            "        [   82],\n",
            "        [ 1871],\n",
            "        [16323],\n",
            "        [    8],\n",
            "        [ 5465],\n",
            "        [ 2379],\n",
            "        [ 7814],\n",
            "        [  166],\n",
            "        [  615],\n",
            "        [26979],\n",
            "        [  398],\n",
            "        [   16],\n",
            "        [22605],\n",
            "        [  923],\n",
            "        [  149],\n",
            "        [  391],\n",
            "        [  135],\n",
            "        [21627],\n",
            "        [    7],\n",
            "        [ 1475],\n",
            "        [  282],\n",
            "        [13489],\n",
            "        [ 1835],\n",
            "        [28804],\n",
            "        [  388],\n",
            "        [28196],\n",
            "        [  539],\n",
            "        [16777],\n",
            "        [   61],\n",
            "        [    9],\n",
            "        [  831],\n",
            "        [19948],\n",
            "        [    1],\n",
            "        [  771],\n",
            "        [   61],\n",
            "        [  274],\n",
            "        [ 1118],\n",
            "        [ 1980],\n",
            "        [  351],\n",
            "        [ 1767],\n",
            "        [  262],\n",
            "        [  659],\n",
            "        [ 1076],\n",
            "        [   18],\n",
            "        [ 2099],\n",
            "        [  295],\n",
            "        [  163],\n",
            "        [   99],\n",
            "        [   23],\n",
            "        [  804],\n",
            "        [ 1820],\n",
            "        [   19],\n",
            "        [   15],\n",
            "        [  297],\n",
            "        [  416],\n",
            "        [   22],\n",
            "        [   87],\n",
            "        [21751],\n",
            "        [   22],\n",
            "        [ 4240],\n",
            "        [ 8343],\n",
            "        [ 1016],\n",
            "        [ 1044],\n",
            "        [  231],\n",
            "        [25516],\n",
            "        [  169]])\n",
            "tensor([1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
            "        1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
            "        0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
            "        0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
            "        1., 1., 0., 0., 0., 1., 1., 0., 0., 1.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[19380],\n",
            "        [  117],\n",
            "        [  280],\n",
            "        [  218],\n",
            "        [ 2492],\n",
            "        [  953],\n",
            "        [   74],\n",
            "        [ 5138],\n",
            "        [ 3190],\n",
            "        [  372],\n",
            "        [   67],\n",
            "        [  117],\n",
            "        [ 3891],\n",
            "        [   61],\n",
            "        [  976],\n",
            "        [ 1543],\n",
            "        [   77],\n",
            "        [  760],\n",
            "        [  619],\n",
            "        [14543],\n",
            "        [ 7707],\n",
            "        [  634],\n",
            "        [  212],\n",
            "        [ 2458],\n",
            "        [  169],\n",
            "        [  402],\n",
            "        [    4],\n",
            "        [ 4637],\n",
            "        [  126],\n",
            "        [  167],\n",
            "        [  153],\n",
            "        [   61],\n",
            "        [25845],\n",
            "        [   41],\n",
            "        [    5],\n",
            "        [29056],\n",
            "        [   61],\n",
            "        [   33],\n",
            "        [   24],\n",
            "        [   27],\n",
            "        [   65],\n",
            "        [  542],\n",
            "        [ 2842],\n",
            "        [ 3634],\n",
            "        [  753],\n",
            "        [ 4923],\n",
            "        [19047],\n",
            "        [  116],\n",
            "        [  355],\n",
            "        [ 4376],\n",
            "        [   18],\n",
            "        [  305],\n",
            "        [  114],\n",
            "        [  111],\n",
            "        [ 1107],\n",
            "        [  191],\n",
            "        [ 1394],\n",
            "        [ 5415],\n",
            "        [   40],\n",
            "        [   60],\n",
            "        [  142],\n",
            "        [    1],\n",
            "        [  880],\n",
            "        [ 2137],\n",
            "        [  441],\n",
            "        [ 4278],\n",
            "        [26791],\n",
            "        [   34],\n",
            "        [ 1169],\n",
            "        [    1],\n",
            "        [ 8946],\n",
            "        [ 1547],\n",
            "        [   81],\n",
            "        [  588],\n",
            "        [  158],\n",
            "        [ 3402],\n",
            "        [  132],\n",
            "        [15571],\n",
            "        [26988],\n",
            "        [21215],\n",
            "        [ 4189],\n",
            "        [ 4415],\n",
            "        [   44],\n",
            "        [ 2662],\n",
            "        [ 2615],\n",
            "        [ 7895],\n",
            "        [   35],\n",
            "        [  287],\n",
            "        [  620],\n",
            "        [  733],\n",
            "        [  215],\n",
            "        [   61],\n",
            "        [   61],\n",
            "        [   14],\n",
            "        [  124],\n",
            "        [   61],\n",
            "        [ 9319],\n",
            "        [  411],\n",
            "        [  324],\n",
            "        [   34]])\n",
            "tensor([0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
            "        0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
            "        0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
            "        1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
            "        1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[ 1601],\n",
            "        [  812],\n",
            "        [  971],\n",
            "        [  155],\n",
            "        [  519],\n",
            "        [   64],\n",
            "        [  117],\n",
            "        [   27],\n",
            "        [   45],\n",
            "        [ 2227],\n",
            "        [ 5167],\n",
            "        [   14],\n",
            "        [   99],\n",
            "        [ 8199],\n",
            "        [ 2182],\n",
            "        [15573],\n",
            "        [  489],\n",
            "        [  158],\n",
            "        [ 2502],\n",
            "        [ 2148],\n",
            "        [    3],\n",
            "        [   45],\n",
            "        [  217],\n",
            "        [21775],\n",
            "        [    1],\n",
            "        [   64],\n",
            "        [  117],\n",
            "        [ 1307],\n",
            "        [ 5597],\n",
            "        [   96],\n",
            "        [  117],\n",
            "        [25968],\n",
            "        [ 6469],\n",
            "        [ 5337],\n",
            "        [    1],\n",
            "        [   35],\n",
            "        [ 1028],\n",
            "        [   61],\n",
            "        [  237],\n",
            "        [   60],\n",
            "        [ 1203],\n",
            "        [  193],\n",
            "        [  257],\n",
            "        [ 1625],\n",
            "        [ 4211],\n",
            "        [  593],\n",
            "        [28601],\n",
            "        [ 2406],\n",
            "        [ 3524],\n",
            "        [   61],\n",
            "        [ 1597],\n",
            "        [ 2891],\n",
            "        [24325],\n",
            "        [ 4848],\n",
            "        [ 1104],\n",
            "        [  257],\n",
            "        [  394],\n",
            "        [  390],\n",
            "        [  315],\n",
            "        [  134],\n",
            "        [  562],\n",
            "        [   34],\n",
            "        [ 1850],\n",
            "        [ 2596],\n",
            "        [   86],\n",
            "        [  490],\n",
            "        [ 4863],\n",
            "        [    4],\n",
            "        [10663],\n",
            "        [25387],\n",
            "        [ 1145],\n",
            "        [ 1310],\n",
            "        [   96],\n",
            "        [   18],\n",
            "        [10248],\n",
            "        [ 2603],\n",
            "        [  356],\n",
            "        [  525],\n",
            "        [ 1820],\n",
            "        [ 1275],\n",
            "        [20984],\n",
            "        [   11],\n",
            "        [   61],\n",
            "        [  180],\n",
            "        [16598],\n",
            "        [   23],\n",
            "        [   61],\n",
            "        [20251],\n",
            "        [ 3255],\n",
            "        [   34],\n",
            "        [  307],\n",
            "        [23318],\n",
            "        [ 1177],\n",
            "        [  257],\n",
            "        [   47],\n",
            "        [   18],\n",
            "        [  463],\n",
            "        [   25],\n",
            "        [   18],\n",
            "        [  163]])\n",
            "tensor([0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
            "        1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
            "        1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
            "        0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 1., 1., 0., 1., 0., 0., 1., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[ 1265],\n",
            "        [   50],\n",
            "        [ 6073],\n",
            "        [   72],\n",
            "        [  524],\n",
            "        [19808],\n",
            "        [ 1132],\n",
            "        [   24],\n",
            "        [18961],\n",
            "        [ 3366],\n",
            "        [  268],\n",
            "        [   61],\n",
            "        [  677],\n",
            "        [ 2565],\n",
            "        [28599],\n",
            "        [ 4303],\n",
            "        [  961],\n",
            "        [27189],\n",
            "        [ 2944],\n",
            "        [ 2565],\n",
            "        [ 1774],\n",
            "        [ 1016],\n",
            "        [    8],\n",
            "        [   81],\n",
            "        [ 3033],\n",
            "        [ 2815],\n",
            "        [ 8727],\n",
            "        [ 4227],\n",
            "        [16322],\n",
            "        [   33],\n",
            "        [ 1020],\n",
            "        [    1],\n",
            "        [  143],\n",
            "        [ 1040],\n",
            "        [ 2787],\n",
            "        [ 1080],\n",
            "        [   13],\n",
            "        [   44],\n",
            "        [  299],\n",
            "        [  948],\n",
            "        [ 2665],\n",
            "        [   33],\n",
            "        [ 2883],\n",
            "        [  122],\n",
            "        [25062],\n",
            "        [   60],\n",
            "        [    8],\n",
            "        [  139],\n",
            "        [  869],\n",
            "        [  397],\n",
            "        [  146],\n",
            "        [  382],\n",
            "        [  274],\n",
            "        [ 1077],\n",
            "        [ 2308],\n",
            "        [ 5935],\n",
            "        [ 2603],\n",
            "        [   28],\n",
            "        [  467],\n",
            "        [   95],\n",
            "        [ 4854],\n",
            "        [  902],\n",
            "        [ 1411],\n",
            "        [  228],\n",
            "        [   79],\n",
            "        [  870],\n",
            "        [ 1730],\n",
            "        [  113],\n",
            "        [ 1672],\n",
            "        [   67],\n",
            "        [ 2933],\n",
            "        [  483],\n",
            "        [14619],\n",
            "        [ 3318],\n",
            "        [20995],\n",
            "        [ 1712],\n",
            "        [ 1223],\n",
            "        [    5],\n",
            "        [  246],\n",
            "        [   41],\n",
            "        [  138],\n",
            "        [  111],\n",
            "        [ 3582],\n",
            "        [    1],\n",
            "        [   61],\n",
            "        [ 1512],\n",
            "        [  496],\n",
            "        [23036],\n",
            "        [  169],\n",
            "        [19319],\n",
            "        [  169],\n",
            "        [  160],\n",
            "        [ 1744],\n",
            "        [   30],\n",
            "        [   82],\n",
            "        [   29],\n",
            "        [  448],\n",
            "        [  594],\n",
            "        [   25],\n",
            "        [  186]])\n",
            "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
            "        0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
            "        1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
            "        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
            "        1., 1., 0., 1., 0., 1., 0., 0., 1., 1.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[   75],\n",
            "        [ 2219],\n",
            "        [ 1211],\n",
            "        [ 2335],\n",
            "        [ 3708],\n",
            "        [ 2891],\n",
            "        [ 4083],\n",
            "        [21255],\n",
            "        [  288],\n",
            "        [    5],\n",
            "        [  167],\n",
            "        [11196],\n",
            "        [   98],\n",
            "        [  367],\n",
            "        [  153],\n",
            "        [ 1710],\n",
            "        [  420],\n",
            "        [   29],\n",
            "        [    1],\n",
            "        [  998],\n",
            "        [  659],\n",
            "        [   76],\n",
            "        [ 1128],\n",
            "        [  124],\n",
            "        [10174],\n",
            "        [  580],\n",
            "        [ 1466],\n",
            "        [   16],\n",
            "        [  117],\n",
            "        [  527],\n",
            "        [   67],\n",
            "        [ 1018],\n",
            "        [ 2738],\n",
            "        [    8],\n",
            "        [ 1786],\n",
            "        [   82],\n",
            "        [13067],\n",
            "        [    5],\n",
            "        [ 1991],\n",
            "        [   19],\n",
            "        [ 3921],\n",
            "        [  259],\n",
            "        [  306],\n",
            "        [   61],\n",
            "        [  621],\n",
            "        [  140],\n",
            "        [  632],\n",
            "        [  104],\n",
            "        [    5],\n",
            "        [  428],\n",
            "        [  246],\n",
            "        [  591],\n",
            "        [    9],\n",
            "        [ 1138],\n",
            "        [ 1027],\n",
            "        [  211],\n",
            "        [  312],\n",
            "        [  117],\n",
            "        [  324],\n",
            "        [  138],\n",
            "        [    8],\n",
            "        [   81],\n",
            "        [25491],\n",
            "        [   76],\n",
            "        [  519],\n",
            "        [ 2970],\n",
            "        [  179],\n",
            "        [ 5286],\n",
            "        [19731],\n",
            "        [   81],\n",
            "        [   10],\n",
            "        [  108],\n",
            "        [ 6685],\n",
            "        [  380],\n",
            "        [   95],\n",
            "        [  260],\n",
            "        [ 5443],\n",
            "        [   66],\n",
            "        [17615],\n",
            "        [  919],\n",
            "        [   16],\n",
            "        [  356],\n",
            "        [   28],\n",
            "        [  853],\n",
            "        [  870],\n",
            "        [   14],\n",
            "        [ 1470],\n",
            "        [    4],\n",
            "        [ 5948],\n",
            "        [  117],\n",
            "        [ 2605],\n",
            "        [  388],\n",
            "        [ 5167],\n",
            "        [  462],\n",
            "        [  870],\n",
            "        [23241],\n",
            "        [  649],\n",
            "        [ 1629],\n",
            "        [   82],\n",
            "        [   25]])\n",
            "tensor([0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
            "        1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
            "        1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
            "        1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
            "        1., 0., 0., 0., 1., 0., 0., 0., 1., 1.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[23875],\n",
            "        [  802],\n",
            "        [ 2712],\n",
            "        [   64],\n",
            "        [   18],\n",
            "        [ 5350],\n",
            "        [ 1231],\n",
            "        [  297],\n",
            "        [  951],\n",
            "        [ 7602],\n",
            "        [ 7416],\n",
            "        [ 1237],\n",
            "        [  395],\n",
            "        [   34],\n",
            "        [ 2573],\n",
            "        [  895],\n",
            "        [ 1590],\n",
            "        [ 5621],\n",
            "        [  699],\n",
            "        [  745],\n",
            "        [ 4309],\n",
            "        [  143],\n",
            "        [   16],\n",
            "        [11228],\n",
            "        [    8],\n",
            "        [16643],\n",
            "        [  460],\n",
            "        [   63],\n",
            "        [   18],\n",
            "        [    8],\n",
            "        [   21],\n",
            "        [ 1946],\n",
            "        [  680],\n",
            "        [   94],\n",
            "        [  376],\n",
            "        [   61],\n",
            "        [   49],\n",
            "        [   21],\n",
            "        [   11],\n",
            "        [ 1730],\n",
            "        [    8],\n",
            "        [  212],\n",
            "        [  102],\n",
            "        [  199],\n",
            "        [  735],\n",
            "        [   61],\n",
            "        [ 1602],\n",
            "        [ 2719],\n",
            "        [  733],\n",
            "        [22904],\n",
            "        [  374],\n",
            "        [  750],\n",
            "        [ 5541],\n",
            "        [   61],\n",
            "        [    9],\n",
            "        [  970],\n",
            "        [  356],\n",
            "        [  951],\n",
            "        [   25],\n",
            "        [  374],\n",
            "        [  117],\n",
            "        [  134],\n",
            "        [   87],\n",
            "        [  644],\n",
            "        [  126],\n",
            "        [  818],\n",
            "        [  859],\n",
            "        [   81],\n",
            "        [  112],\n",
            "        [   28],\n",
            "        [  249],\n",
            "        [  956],\n",
            "        [   89],\n",
            "        [  237],\n",
            "        [ 1231],\n",
            "        [  612],\n",
            "        [   28],\n",
            "        [  556],\n",
            "        [ 2758],\n",
            "        [    5],\n",
            "        [  299],\n",
            "        [  380],\n",
            "        [    9],\n",
            "        [  269],\n",
            "        [24353],\n",
            "        [   55],\n",
            "        [   21],\n",
            "        [   21],\n",
            "        [ 2414],\n",
            "        [   44],\n",
            "        [    4],\n",
            "        [23592],\n",
            "        [  542],\n",
            "        [ 1108],\n",
            "        [ 7334],\n",
            "        [12324],\n",
            "        [    7],\n",
            "        [  300],\n",
            "        [   98],\n",
            "        [12419]])\n",
            "tensor([1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
            "        1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
            "        0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
            "        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0.,\n",
            "        0., 1., 1., 0., 0., 0., 0., 1., 1., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[ 6121],\n",
            "        [  163],\n",
            "        [10299],\n",
            "        [  224],\n",
            "        [   82],\n",
            "        [   81],\n",
            "        [  356],\n",
            "        [  161],\n",
            "        [26406],\n",
            "        [ 1168],\n",
            "        [  384],\n",
            "        [   29],\n",
            "        [   65],\n",
            "        [ 2046],\n",
            "        [   81],\n",
            "        [ 3319],\n",
            "        [  993],\n",
            "        [  146],\n",
            "        [  333],\n",
            "        [  394],\n",
            "        [ 3647],\n",
            "        [   13],\n",
            "        [   33],\n",
            "        [ 9129],\n",
            "        [   26],\n",
            "        [   50],\n",
            "        [  157],\n",
            "        [    8],\n",
            "        [  174],\n",
            "        [   35],\n",
            "        [ 2320],\n",
            "        [   77],\n",
            "        [   16],\n",
            "        [   32],\n",
            "        [    1],\n",
            "        [ 2918],\n",
            "        [   64],\n",
            "        [ 2698],\n",
            "        [  998],\n",
            "        [  162],\n",
            "        [  297],\n",
            "        [ 3670],\n",
            "        [  119],\n",
            "        [   56],\n",
            "        [   19],\n",
            "        [  153],\n",
            "        [ 8242],\n",
            "        [  151],\n",
            "        [   13],\n",
            "        [  530],\n",
            "        [  354],\n",
            "        [  385],\n",
            "        [  116],\n",
            "        [ 4617],\n",
            "        [21121],\n",
            "        [  176],\n",
            "        [  224],\n",
            "        [  246],\n",
            "        [ 2554],\n",
            "        [21266],\n",
            "        [ 2598],\n",
            "        [  553],\n",
            "        [ 1949],\n",
            "        [  414],\n",
            "        [   26],\n",
            "        [   11],\n",
            "        [   72],\n",
            "        [ 8530],\n",
            "        [19171],\n",
            "        [  161],\n",
            "        [   46],\n",
            "        [ 3026],\n",
            "        [ 2890],\n",
            "        [  959],\n",
            "        [  151],\n",
            "        [   61],\n",
            "        [  394],\n",
            "        [   44],\n",
            "        [20485],\n",
            "        [ 1144],\n",
            "        [    1],\n",
            "        [   60],\n",
            "        [ 3547],\n",
            "        [25826],\n",
            "        [   11],\n",
            "        [  231],\n",
            "        [   16],\n",
            "        [11204],\n",
            "        [ 1714],\n",
            "        [ 4127],\n",
            "        [ 5439],\n",
            "        [  329],\n",
            "        [ 6960],\n",
            "        [  833],\n",
            "        [   18],\n",
            "        [ 2587],\n",
            "        [   84],\n",
            "        [  264],\n",
            "        [ 2048],\n",
            "        [  495]])\n",
            "tensor([0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
            "        1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
            "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
            "        0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
            "        0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
            "        1., 1., 1., 0., 0., 1., 1., 0., 1., 1.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[22671],\n",
            "        [  679],\n",
            "        [  960],\n",
            "        [  309],\n",
            "        [ 3022],\n",
            "        [   41],\n",
            "        [   63],\n",
            "        [  367],\n",
            "        [ 1859],\n",
            "        [  478],\n",
            "        [   61],\n",
            "        [   98],\n",
            "        [  828],\n",
            "        [ 2804],\n",
            "        [ 8713],\n",
            "        [ 1031],\n",
            "        [  111],\n",
            "        [  194],\n",
            "        [   28],\n",
            "        [19387],\n",
            "        [ 1888],\n",
            "        [ 2089],\n",
            "        [  400],\n",
            "        [  537],\n",
            "        [ 5556],\n",
            "        [  126],\n",
            "        [ 2408],\n",
            "        [  117],\n",
            "        [ 2277],\n",
            "        [   81],\n",
            "        [  305],\n",
            "        [ 1497],\n",
            "        [  268],\n",
            "        [   61],\n",
            "        [    7],\n",
            "        [10075],\n",
            "        [28676],\n",
            "        [28420],\n",
            "        [  330],\n",
            "        [  620],\n",
            "        [   79],\n",
            "        [ 1027],\n",
            "        [11072],\n",
            "        [  268],\n",
            "        [ 1269],\n",
            "        [  117],\n",
            "        [23539],\n",
            "        [  298],\n",
            "        [29001],\n",
            "        [ 1125],\n",
            "        [27165],\n",
            "        [ 1437],\n",
            "        [   56],\n",
            "        [    5],\n",
            "        [  685],\n",
            "        [  731],\n",
            "        [19144],\n",
            "        [ 5905],\n",
            "        [    8],\n",
            "        [  352],\n",
            "        [  143],\n",
            "        [24211],\n",
            "        [ 1301],\n",
            "        [   13],\n",
            "        [22463],\n",
            "        [28289],\n",
            "        [ 4680],\n",
            "        [  435],\n",
            "        [   43],\n",
            "        [ 1021],\n",
            "        [    1],\n",
            "        [    7],\n",
            "        [   90],\n",
            "        [ 2615],\n",
            "        [ 1820],\n",
            "        [ 7894],\n",
            "        [   65],\n",
            "        [25952],\n",
            "        [ 3249],\n",
            "        [  142],\n",
            "        [  551],\n",
            "        [  478],\n",
            "        [   18],\n",
            "        [  675],\n",
            "        [13116],\n",
            "        [  104],\n",
            "        [  702],\n",
            "        [  492],\n",
            "        [  201],\n",
            "        [    1],\n",
            "        [ 2687],\n",
            "        [  169],\n",
            "        [   11],\n",
            "        [ 7534],\n",
            "        [   61],\n",
            "        [  134],\n",
            "        [   81],\n",
            "        [  338],\n",
            "        [  701],\n",
            "        [   31]])\n",
            "tensor([0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
            "        0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
            "        0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0.,\n",
            "        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
            "        0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        1., 1., 1., 1., 0., 1., 1., 1., 1., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[   61],\n",
            "        [  108],\n",
            "        [   61],\n",
            "        [ 4469],\n",
            "        [ 2831],\n",
            "        [ 6480],\n",
            "        [10843],\n",
            "        [ 5330],\n",
            "        [  727],\n",
            "        [  356],\n",
            "        [  146],\n",
            "        [   77],\n",
            "        [22582],\n",
            "        [  217],\n",
            "        [  125],\n",
            "        [   82],\n",
            "        [ 1259],\n",
            "        [   83],\n",
            "        [17007],\n",
            "        [ 1090],\n",
            "        [   35],\n",
            "        [  191],\n",
            "        [ 1903],\n",
            "        [  153],\n",
            "        [   41],\n",
            "        [   75],\n",
            "        [   35],\n",
            "        [   73],\n",
            "        [ 1097],\n",
            "        [  129],\n",
            "        [ 8923],\n",
            "        [  837],\n",
            "        [  114],\n",
            "        [  338],\n",
            "        [16435],\n",
            "        [  581],\n",
            "        [ 6023],\n",
            "        [ 1047],\n",
            "        [  122],\n",
            "        [   11],\n",
            "        [  264],\n",
            "        [   16],\n",
            "        [  585],\n",
            "        [  117],\n",
            "        [  500],\n",
            "        [ 4822],\n",
            "        [   28],\n",
            "        [25550],\n",
            "        [   18],\n",
            "        [ 2602],\n",
            "        [  499],\n",
            "        [ 6741],\n",
            "        [   79],\n",
            "        [27510],\n",
            "        [21335],\n",
            "        [ 1993],\n",
            "        [  307],\n",
            "        [ 1084],\n",
            "        [ 3173],\n",
            "        [  563],\n",
            "        [  138],\n",
            "        [ 2855],\n",
            "        [ 3880],\n",
            "        [  292],\n",
            "        [19190],\n",
            "        [  592],\n",
            "        [   13],\n",
            "        [24717],\n",
            "        [12038],\n",
            "        [   56],\n",
            "        [   18],\n",
            "        [    8],\n",
            "        [   18],\n",
            "        [24223],\n",
            "        [  894],\n",
            "        [   21],\n",
            "        [  355],\n",
            "        [ 1879],\n",
            "        [23263],\n",
            "        [   28],\n",
            "        [16971],\n",
            "        [ 5142],\n",
            "        [24899],\n",
            "        [ 1150],\n",
            "        [  312],\n",
            "        [ 2106],\n",
            "        [ 1181],\n",
            "        [   89],\n",
            "        [18022],\n",
            "        [ 7393],\n",
            "        [  180],\n",
            "        [   19],\n",
            "        [ 8673],\n",
            "        [ 2116],\n",
            "        [ 2366],\n",
            "        [    5],\n",
            "        [    9],\n",
            "        [  318],\n",
            "        [   90],\n",
            "        [ 1269]])\n",
            "tensor([0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
            "        0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
            "        1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
            "        0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
            "        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
            "        1., 1., 1., 1., 0., 0., 1., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[ 1653],\n",
            "        [ 7268],\n",
            "        [  255],\n",
            "        [  611],\n",
            "        [   18],\n",
            "        [ 2148],\n",
            "        [  757],\n",
            "        [   57],\n",
            "        [ 7227],\n",
            "        [  231],\n",
            "        [ 1287],\n",
            "        [   24],\n",
            "        [  682],\n",
            "        [   60],\n",
            "        [  245],\n",
            "        [  786],\n",
            "        [22260],\n",
            "        [29112],\n",
            "        [   23],\n",
            "        [  153],\n",
            "        [  396],\n",
            "        [   40],\n",
            "        [  421],\n",
            "        [  468],\n",
            "        [21756],\n",
            "        [25469],\n",
            "        [ 4023],\n",
            "        [ 1321],\n",
            "        [ 2967],\n",
            "        [24952],\n",
            "        [ 2134],\n",
            "        [   19],\n",
            "        [ 1577],\n",
            "        [   14],\n",
            "        [  108],\n",
            "        [  592],\n",
            "        [   25],\n",
            "        [  537],\n",
            "        [ 4622],\n",
            "        [   27],\n",
            "        [  133],\n",
            "        [ 1738],\n",
            "        [  658],\n",
            "        [   77],\n",
            "        [ 7947],\n",
            "        [ 1176],\n",
            "        [ 5879],\n",
            "        [  990],\n",
            "        [  556],\n",
            "        [  246],\n",
            "        [ 1775],\n",
            "        [ 1112],\n",
            "        [  117],\n",
            "        [   16],\n",
            "        [  685],\n",
            "        [    8],\n",
            "        [   98],\n",
            "        [19108],\n",
            "        [  678],\n",
            "        [  204],\n",
            "        [   41],\n",
            "        [ 1832],\n",
            "        [ 1529],\n",
            "        [   28],\n",
            "        [  338],\n",
            "        [  149],\n",
            "        [   29],\n",
            "        [  204],\n",
            "        [26799],\n",
            "        [   18],\n",
            "        [ 8351],\n",
            "        [   41],\n",
            "        [ 3660],\n",
            "        [  163],\n",
            "        [   36],\n",
            "        [  177],\n",
            "        [ 3910],\n",
            "        [  246],\n",
            "        [   24],\n",
            "        [   16],\n",
            "        [   86],\n",
            "        [   81],\n",
            "        [ 3026],\n",
            "        [ 2047],\n",
            "        [    1],\n",
            "        [  258],\n",
            "        [  191],\n",
            "        [  259],\n",
            "        [ 4144],\n",
            "        [ 8499],\n",
            "        [   23],\n",
            "        [  578],\n",
            "        [ 2345],\n",
            "        [ 2718],\n",
            "        [  193],\n",
            "        [  352],\n",
            "        [   41],\n",
            "        [  520],\n",
            "        [   59],\n",
            "        [   16]])\n",
            "tensor([1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
            "        1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
            "        1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
            "        0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
            "        1., 1., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[   21],\n",
            "        [ 1973],\n",
            "        [  212],\n",
            "        [  237],\n",
            "        [  201],\n",
            "        [ 1649],\n",
            "        [   16],\n",
            "        [ 3634],\n",
            "        [   11],\n",
            "        [ 9883],\n",
            "        [   22],\n",
            "        [   31],\n",
            "        [  280],\n",
            "        [  259],\n",
            "        [   43],\n",
            "        [  329],\n",
            "        [  746],\n",
            "        [   56],\n",
            "        [ 1412],\n",
            "        [  675],\n",
            "        [20073],\n",
            "        [  138],\n",
            "        [ 5832],\n",
            "        [13378],\n",
            "        [   18],\n",
            "        [ 1502],\n",
            "        [    5],\n",
            "        [21483],\n",
            "        [   13],\n",
            "        [ 3065],\n",
            "        [ 1266],\n",
            "        [  413],\n",
            "        [ 1496],\n",
            "        [29031],\n",
            "        [ 7560],\n",
            "        [ 1061],\n",
            "        [ 8902],\n",
            "        [ 4664],\n",
            "        [ 1678],\n",
            "        [ 9503],\n",
            "        [   16],\n",
            "        [  292],\n",
            "        [   81],\n",
            "        [  618],\n",
            "        [  146],\n",
            "        [22902],\n",
            "        [  231],\n",
            "        [   41],\n",
            "        [   81],\n",
            "        [  163],\n",
            "        [12470],\n",
            "        [   21],\n",
            "        [   61],\n",
            "        [  212],\n",
            "        [   86],\n",
            "        [  919],\n",
            "        [14716],\n",
            "        [  108],\n",
            "        [ 5268],\n",
            "        [  902],\n",
            "        [10608],\n",
            "        [16520],\n",
            "        [   61],\n",
            "        [   26],\n",
            "        [   40],\n",
            "        [    9],\n",
            "        [   32],\n",
            "        [   75],\n",
            "        [ 2654],\n",
            "        [  169],\n",
            "        [  356],\n",
            "        [   89],\n",
            "        [ 1198],\n",
            "        [ 3118],\n",
            "        [  333],\n",
            "        [ 1859],\n",
            "        [ 1120],\n",
            "        [  388],\n",
            "        [   44],\n",
            "        [    7],\n",
            "        [   76],\n",
            "        [   34],\n",
            "        [ 6289],\n",
            "        [ 1391],\n",
            "        [  177],\n",
            "        [ 2926],\n",
            "        [   79],\n",
            "        [  274],\n",
            "        [  733],\n",
            "        [   13],\n",
            "        [  191],\n",
            "        [ 1254],\n",
            "        [   28],\n",
            "        [   82],\n",
            "        [  237],\n",
            "        [  997],\n",
            "        [   74],\n",
            "        [  290],\n",
            "        [ 9535],\n",
            "        [ 4737]])\n",
            "tensor([1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
            "        0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0.,\n",
            "        0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
            "        1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
            "        0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
            "        1., 0., 0., 0., 0., 1., 0., 1., 0., 1.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[19139],\n",
            "        [ 4035],\n",
            "        [    5],\n",
            "        [    7],\n",
            "        [  494],\n",
            "        [  529],\n",
            "        [  151],\n",
            "        [   86],\n",
            "        [16348],\n",
            "        [ 4428],\n",
            "        [   25],\n",
            "        [  589],\n",
            "        [11265],\n",
            "        [17411],\n",
            "        [  391],\n",
            "        [  122],\n",
            "        [  923],\n",
            "        [  163],\n",
            "        [   89],\n",
            "        [23863],\n",
            "        [  305],\n",
            "        [ 3314],\n",
            "        [  236],\n",
            "        [   13],\n",
            "        [  816],\n",
            "        [  178],\n",
            "        [    1],\n",
            "        [ 1105],\n",
            "        [   16],\n",
            "        [ 3780],\n",
            "        [  285],\n",
            "        [  176],\n",
            "        [   61],\n",
            "        [   27],\n",
            "        [ 1460],\n",
            "        [   10],\n",
            "        [ 5823],\n",
            "        [ 7245],\n",
            "        [  138],\n",
            "        [   65],\n",
            "        [  683],\n",
            "        [ 1819],\n",
            "        [    9],\n",
            "        [   28],\n",
            "        [   28],\n",
            "        [  143],\n",
            "        [ 2718],\n",
            "        [26951],\n",
            "        [   41],\n",
            "        [  123],\n",
            "        [ 5449],\n",
            "        [   49],\n",
            "        [22474],\n",
            "        [  117],\n",
            "        [ 2630],\n",
            "        [  503],\n",
            "        [ 5844],\n",
            "        [  191],\n",
            "        [  113],\n",
            "        [   24],\n",
            "        [  472],\n",
            "        [  138],\n",
            "        [  179],\n",
            "        [ 8818],\n",
            "        [  246],\n",
            "        [ 3950],\n",
            "        [  556],\n",
            "        [ 3076],\n",
            "        [   69],\n",
            "        [  579],\n",
            "        [    1],\n",
            "        [ 1002],\n",
            "        [   19],\n",
            "        [  101],\n",
            "        [  117],\n",
            "        [  146],\n",
            "        [   81],\n",
            "        [  201],\n",
            "        [   79],\n",
            "        [    8],\n",
            "        [   31],\n",
            "        [ 9914],\n",
            "        [  186],\n",
            "        [  153],\n",
            "        [ 2106],\n",
            "        [   40],\n",
            "        [  188],\n",
            "        [  824],\n",
            "        [  231],\n",
            "        [ 5078],\n",
            "        [    4],\n",
            "        [  104],\n",
            "        [  158],\n",
            "        [   61],\n",
            "        [ 2069],\n",
            "        [  380],\n",
            "        [  251],\n",
            "        [   16],\n",
            "        [23452],\n",
            "        [   25]])\n",
            "tensor([1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
            "        0., 0., 1., 0., 0., 1., 0., 0., 0., 1.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[ 5909],\n",
            "        [  126],\n",
            "        [   28],\n",
            "        [16266],\n",
            "        [   44],\n",
            "        [ 3426],\n",
            "        [ 1592],\n",
            "        [   13],\n",
            "        [ 6941],\n",
            "        [  126],\n",
            "        [  356],\n",
            "        [  161],\n",
            "        [ 7287],\n",
            "        [ 4327],\n",
            "        [ 9249],\n",
            "        [   49],\n",
            "        [  964],\n",
            "        [24185],\n",
            "        [  369],\n",
            "        [ 2501],\n",
            "        [   77],\n",
            "        [  383],\n",
            "        [10349],\n",
            "        [ 4803],\n",
            "        [   28],\n",
            "        [ 6876],\n",
            "        [   43],\n",
            "        [  241],\n",
            "        [ 8620],\n",
            "        [   18],\n",
            "        [ 5127],\n",
            "        [  570],\n",
            "        [   11],\n",
            "        [ 4341],\n",
            "        [  213],\n",
            "        [   21],\n",
            "        [    1],\n",
            "        [   46],\n",
            "        [  307],\n",
            "        [ 2755],\n",
            "        [ 1245],\n",
            "        [ 2097],\n",
            "        [  877],\n",
            "        [  219],\n",
            "        [ 2750],\n",
            "        [  384],\n",
            "        [25334],\n",
            "        [  889],\n",
            "        [   65],\n",
            "        [  151],\n",
            "        [  288],\n",
            "        [   32],\n",
            "        [  117],\n",
            "        [  117],\n",
            "        [  295],\n",
            "        [  134],\n",
            "        [   56],\n",
            "        [   73],\n",
            "        [  153],\n",
            "        [  118],\n",
            "        [  117],\n",
            "        [23596],\n",
            "        [ 3303],\n",
            "        [ 1235],\n",
            "        [  114],\n",
            "        [  104],\n",
            "        [    9],\n",
            "        [ 2481],\n",
            "        [    7],\n",
            "        [  142],\n",
            "        [   24],\n",
            "        [  769],\n",
            "        [  868],\n",
            "        [ 4624],\n",
            "        [   25],\n",
            "        [ 3498],\n",
            "        [  571],\n",
            "        [   18],\n",
            "        [24992],\n",
            "        [  997],\n",
            "        [   95],\n",
            "        [  329],\n",
            "        [   56],\n",
            "        [   54],\n",
            "        [  126],\n",
            "        [ 4965],\n",
            "        [20879],\n",
            "        [   78],\n",
            "        [  187],\n",
            "        [ 2444],\n",
            "        [   75],\n",
            "        [  117],\n",
            "        [ 2031],\n",
            "        [   56],\n",
            "        [  462],\n",
            "        [    0],\n",
            "        [   15],\n",
            "        [13442],\n",
            "        [  463],\n",
            "        [ 7107]])\n",
            "tensor([0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
            "        1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
            "        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
            "        0., 0., 1., 1., 0., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[   60],\n",
            "        [11858],\n",
            "        [  230],\n",
            "        [   29],\n",
            "        [    8],\n",
            "        [20024],\n",
            "        [   13],\n",
            "        [  391],\n",
            "        [  607],\n",
            "        [  360],\n",
            "        [  381],\n",
            "        [27380],\n",
            "        [ 1178],\n",
            "        [   30],\n",
            "        [22421],\n",
            "        [   61],\n",
            "        [14167],\n",
            "        [  600],\n",
            "        [11862],\n",
            "        [  149],\n",
            "        [    8],\n",
            "        [  727],\n",
            "        [   11],\n",
            "        [18200],\n",
            "        [  414],\n",
            "        [  192],\n",
            "        [  458],\n",
            "        [ 1835],\n",
            "        [  391],\n",
            "        [  852],\n",
            "        [   84],\n",
            "        [ 4596],\n",
            "        [  114],\n",
            "        [   44],\n",
            "        [   11],\n",
            "        [  804],\n",
            "        [   29],\n",
            "        [  857],\n",
            "        [  297],\n",
            "        [ 8181],\n",
            "        [    1],\n",
            "        [12876],\n",
            "        [ 3916],\n",
            "        [  338],\n",
            "        [ 1316],\n",
            "        [    5],\n",
            "        [ 5687],\n",
            "        [  731],\n",
            "        [18734],\n",
            "        [   94],\n",
            "        [   18],\n",
            "        [   21],\n",
            "        [23753],\n",
            "        [  179],\n",
            "        [    1],\n",
            "        [24530],\n",
            "        [28345],\n",
            "        [  737],\n",
            "        [  868],\n",
            "        [   22],\n",
            "        [   24],\n",
            "        [  344],\n",
            "        [ 4765],\n",
            "        [  114],\n",
            "        [  432],\n",
            "        [ 2119],\n",
            "        [  126],\n",
            "        [  529],\n",
            "        [  287],\n",
            "        [  251],\n",
            "        [ 1324],\n",
            "        [  314],\n",
            "        [ 6382],\n",
            "        [   47],\n",
            "        [  287],\n",
            "        [19905],\n",
            "        [   56],\n",
            "        [   24],\n",
            "        [  272],\n",
            "        [  558],\n",
            "        [  416],\n",
            "        [ 4757],\n",
            "        [ 1203],\n",
            "        [20773],\n",
            "        [ 4438],\n",
            "        [22994],\n",
            "        [   52],\n",
            "        [    9],\n",
            "        [  713],\n",
            "        [  114],\n",
            "        [13434],\n",
            "        [  225],\n",
            "        [ 4624],\n",
            "        [  726],\n",
            "        [15384],\n",
            "        [  282],\n",
            "        [ 2135],\n",
            "        [ 1883],\n",
            "        [  799],\n",
            "        [  143]])\n",
            "tensor([0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
            "        1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
            "        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
            "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
            "        0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 1., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[ 1379],\n",
            "        [  585],\n",
            "        [10408],\n",
            "        [   59],\n",
            "        [ 2306],\n",
            "        [ 3637],\n",
            "        [   81],\n",
            "        [ 3497],\n",
            "        [10440],\n",
            "        [   19],\n",
            "        [  413],\n",
            "        [   18],\n",
            "        [  377],\n",
            "        [  117],\n",
            "        [   61],\n",
            "        [ 9077],\n",
            "        [  149],\n",
            "        [   96],\n",
            "        [ 2191],\n",
            "        [   58],\n",
            "        [  524],\n",
            "        [22610],\n",
            "        [10874],\n",
            "        [21574],\n",
            "        [ 4801],\n",
            "        [  192],\n",
            "        [    4],\n",
            "        [ 1280],\n",
            "        [   61],\n",
            "        [18728],\n",
            "        [  724],\n",
            "        [   13],\n",
            "        [   31],\n",
            "        [   77],\n",
            "        [   43],\n",
            "        [ 4656],\n",
            "        [   19],\n",
            "        [  132],\n",
            "        [ 1494],\n",
            "        [ 1938],\n",
            "        [   38],\n",
            "        [ 2236],\n",
            "        [18467],\n",
            "        [ 1345],\n",
            "        [   19],\n",
            "        [    5],\n",
            "        [   15],\n",
            "        [   60],\n",
            "        [ 1177],\n",
            "        [  305],\n",
            "        [ 5597],\n",
            "        [   60],\n",
            "        [   72],\n",
            "        [  452],\n",
            "        [  786],\n",
            "        [   68],\n",
            "        [  468],\n",
            "        [  551],\n",
            "        [   11],\n",
            "        [ 6673],\n",
            "        [11074],\n",
            "        [ 1244],\n",
            "        [   36],\n",
            "        [  700],\n",
            "        [  295],\n",
            "        [   87],\n",
            "        [  134],\n",
            "        [  160],\n",
            "        [   30],\n",
            "        [  140],\n",
            "        [ 2376],\n",
            "        [  551],\n",
            "        [  477],\n",
            "        [  101],\n",
            "        [ 9194],\n",
            "        [  609],\n",
            "        [  180],\n",
            "        [ 2550],\n",
            "        [  394],\n",
            "        [   16],\n",
            "        [   49],\n",
            "        [  870],\n",
            "        [   79],\n",
            "        [   28],\n",
            "        [  317],\n",
            "        [ 4498],\n",
            "        [  163],\n",
            "        [   16],\n",
            "        [  940],\n",
            "        [   50],\n",
            "        [12321],\n",
            "        [26352],\n",
            "        [ 3278],\n",
            "        [   11],\n",
            "        [ 2582],\n",
            "        [  414],\n",
            "        [ 5353],\n",
            "        [  303],\n",
            "        [  153],\n",
            "        [   87]])\n",
            "tensor([1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
            "        1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
            "        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 1., 0., 0., 1., 0., 1., 1.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[  135],\n",
            "        [ 2282],\n",
            "        [  525],\n",
            "        [  344],\n",
            "        [22458],\n",
            "        [   28],\n",
            "        [  114],\n",
            "        [  537],\n",
            "        [ 8361],\n",
            "        [ 4305],\n",
            "        [18823],\n",
            "        [   31],\n",
            "        [ 1145],\n",
            "        [  158],\n",
            "        [   40],\n",
            "        [16353],\n",
            "        [   16],\n",
            "        [  251],\n",
            "        [ 1651],\n",
            "        [  748],\n",
            "        [ 1327],\n",
            "        [   49],\n",
            "        [   64],\n",
            "        [12807],\n",
            "        [   61],\n",
            "        [  538],\n",
            "        [  117],\n",
            "        [  279],\n",
            "        [27244],\n",
            "        [23312],\n",
            "        [  146],\n",
            "        [   24],\n",
            "        [ 1366],\n",
            "        [  198],\n",
            "        [   61],\n",
            "        [ 2048],\n",
            "        [ 2289],\n",
            "        [    5],\n",
            "        [   22],\n",
            "        [  411],\n",
            "        [   61],\n",
            "        [  185],\n",
            "        [  374],\n",
            "        [   98],\n",
            "        [  142],\n",
            "        [16708],\n",
            "        [ 1475],\n",
            "        [ 1746],\n",
            "        [ 1377],\n",
            "        [   16],\n",
            "        [   89],\n",
            "        [   57],\n",
            "        [  302],\n",
            "        [ 1984],\n",
            "        [   22],\n",
            "        [22140],\n",
            "        [ 8639],\n",
            "        [  374],\n",
            "        [  537],\n",
            "        [  631],\n",
            "        [   29],\n",
            "        [ 6160],\n",
            "        [   77],\n",
            "        [  130],\n",
            "        [  303],\n",
            "        [19458],\n",
            "        [ 1709],\n",
            "        [ 1049],\n",
            "        [  198],\n",
            "        [  960],\n",
            "        [ 1772],\n",
            "        [   40],\n",
            "        [23622],\n",
            "        [  134],\n",
            "        [   96],\n",
            "        [  678],\n",
            "        [  389],\n",
            "        [ 2761],\n",
            "        [  238],\n",
            "        [  224],\n",
            "        [   56],\n",
            "        [    5],\n",
            "        [   94],\n",
            "        [    1],\n",
            "        [    5],\n",
            "        [12402],\n",
            "        [   16],\n",
            "        [  269],\n",
            "        [19480],\n",
            "        [ 6595],\n",
            "        [ 6918],\n",
            "        [   41],\n",
            "        [   11],\n",
            "        [   24],\n",
            "        [ 6505],\n",
            "        [ 4378],\n",
            "        [   64],\n",
            "        [22553],\n",
            "        [    1],\n",
            "        [  260]])\n",
            "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
            "        0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
            "        1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
            "        0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
            "        0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
            "        0., 0., 1., 0., 0., 1., 1., 1., 1., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[  420],\n",
            "        [23566],\n",
            "        [  400],\n",
            "        [  232],\n",
            "        [  468],\n",
            "        [ 1778],\n",
            "        [  157],\n",
            "        [  257],\n",
            "        [ 2435],\n",
            "        [15047],\n",
            "        [ 3114],\n",
            "        [  653],\n",
            "        [  218],\n",
            "        [   60],\n",
            "        [   61],\n",
            "        [ 1427],\n",
            "        [ 7018],\n",
            "        [   81],\n",
            "        [   40],\n",
            "        [   25],\n",
            "        [   87],\n",
            "        [  165],\n",
            "        [  370],\n",
            "        [ 1010],\n",
            "        [ 1214],\n",
            "        [ 3801],\n",
            "        [ 3765],\n",
            "        [  439],\n",
            "        [  502],\n",
            "        [15102],\n",
            "        [   98],\n",
            "        [21207],\n",
            "        [  346],\n",
            "        [  683],\n",
            "        [ 2828],\n",
            "        [ 5920],\n",
            "        [   31],\n",
            "        [    5],\n",
            "        [  177],\n",
            "        [ 1051],\n",
            "        [17595],\n",
            "        [  191],\n",
            "        [   11],\n",
            "        [    7],\n",
            "        [  693],\n",
            "        [ 2069],\n",
            "        [  111],\n",
            "        [   75],\n",
            "        [20134],\n",
            "        [ 3294],\n",
            "        [    7],\n",
            "        [    8],\n",
            "        [ 1447],\n",
            "        [  225],\n",
            "        [    4],\n",
            "        [ 2119],\n",
            "        [  116],\n",
            "        [   43],\n",
            "        [   40],\n",
            "        [ 1111],\n",
            "        [   26],\n",
            "        [  775],\n",
            "        [  527],\n",
            "        [  428],\n",
            "        [ 7098],\n",
            "        [  198],\n",
            "        [   26],\n",
            "        [  108],\n",
            "        [   16],\n",
            "        [ 1686],\n",
            "        [  799],\n",
            "        [  381],\n",
            "        [   69],\n",
            "        [  193],\n",
            "        [  687],\n",
            "        [29028],\n",
            "        [   34],\n",
            "        [  573],\n",
            "        [ 9345],\n",
            "        [ 1066],\n",
            "        [21172],\n",
            "        [ 7417],\n",
            "        [ 7445],\n",
            "        [ 4392],\n",
            "        [ 2392],\n",
            "        [22756],\n",
            "        [   64],\n",
            "        [  680],\n",
            "        [   14],\n",
            "        [  310],\n",
            "        [ 2611],\n",
            "        [  674],\n",
            "        [   61],\n",
            "        [17583],\n",
            "        [  102],\n",
            "        [  753],\n",
            "        [26676],\n",
            "        [ 4860],\n",
            "        [ 8206],\n",
            "        [  117]])\n",
            "tensor([1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
            "        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
            "        0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 1., 1., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[ 6782],\n",
            "        [   22],\n",
            "        [   26],\n",
            "        [17198],\n",
            "        [  148],\n",
            "        [ 2033],\n",
            "        [    8],\n",
            "        [ 9835],\n",
            "        [ 4304],\n",
            "        [   60],\n",
            "        [ 3169],\n",
            "        [    1],\n",
            "        [   40],\n",
            "        [   19],\n",
            "        [   26],\n",
            "        [ 6488],\n",
            "        [   46],\n",
            "        [ 1269],\n",
            "        [ 1308],\n",
            "        [  312],\n",
            "        [ 1036],\n",
            "        [    8],\n",
            "        [   60],\n",
            "        [   11],\n",
            "        [ 2712],\n",
            "        [  759],\n",
            "        [ 7086],\n",
            "        [  117],\n",
            "        [  298],\n",
            "        [    1],\n",
            "        [  146],\n",
            "        [   10],\n",
            "        [22401],\n",
            "        [ 3875],\n",
            "        [  633],\n",
            "        [ 2301],\n",
            "        [ 4434],\n",
            "        [ 3934],\n",
            "        [   28],\n",
            "        [  384],\n",
            "        [15724],\n",
            "        [  626],\n",
            "        [ 9071],\n",
            "        [  789],\n",
            "        [   49],\n",
            "        [   24],\n",
            "        [ 2128],\n",
            "        [  866],\n",
            "        [  295],\n",
            "        [  370],\n",
            "        [ 1293],\n",
            "        [  154],\n",
            "        [  466],\n",
            "        [20632],\n",
            "        [   31],\n",
            "        [ 1265],\n",
            "        [  301],\n",
            "        [ 3913],\n",
            "        [  313],\n",
            "        [  179],\n",
            "        [  628],\n",
            "        [  272],\n",
            "        [16782],\n",
            "        [  374],\n",
            "        [ 2787],\n",
            "        [   19],\n",
            "        [  146],\n",
            "        [   77],\n",
            "        [  126],\n",
            "        [  310],\n",
            "        [ 4067],\n",
            "        [  563],\n",
            "        [   13],\n",
            "        [ 1122],\n",
            "        [   21],\n",
            "        [10436],\n",
            "        [ 1986],\n",
            "        [  517],\n",
            "        [15626],\n",
            "        [ 2227],\n",
            "        [ 4082],\n",
            "        [  576],\n",
            "        [  308],\n",
            "        [  838],\n",
            "        [  295],\n",
            "        [  477],\n",
            "        [   56],\n",
            "        [  365],\n",
            "        [   30],\n",
            "        [  134],\n",
            "        [  962],\n",
            "        [  387],\n",
            "        [ 4276],\n",
            "        [    8],\n",
            "        [ 1018],\n",
            "        [   33],\n",
            "        [  604],\n",
            "        [   72],\n",
            "        [10909],\n",
            "        [22028]])\n",
            "tensor([0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
            "        0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
            "        0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
            "        0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
            "        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
            "        0., 0., 0., 1., 0., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[ 1040],\n",
            "        [ 5687],\n",
            "        [ 1059],\n",
            "        [    8],\n",
            "        [   49],\n",
            "        [   81],\n",
            "        [   73],\n",
            "        [   75],\n",
            "        [   27],\n",
            "        [ 1423],\n",
            "        [10531],\n",
            "        [    1],\n",
            "        [15358],\n",
            "        [  108],\n",
            "        [  670],\n",
            "        [  259],\n",
            "        [ 9093],\n",
            "        [  812],\n",
            "        [ 6130],\n",
            "        [  191],\n",
            "        [ 7988],\n",
            "        [   43],\n",
            "        [20869],\n",
            "        [  733],\n",
            "        [  432],\n",
            "        [    5],\n",
            "        [  104],\n",
            "        [ 2711],\n",
            "        [   96],\n",
            "        [   61],\n",
            "        [   23],\n",
            "        [  754],\n",
            "        [    9],\n",
            "        [ 7382],\n",
            "        [  419],\n",
            "        [  116],\n",
            "        [  616],\n",
            "        [  741],\n",
            "        [   49],\n",
            "        [11096],\n",
            "        [ 2106],\n",
            "        [   14],\n",
            "        [  117],\n",
            "        [   13],\n",
            "        [  926],\n",
            "        [ 1053],\n",
            "        [  462],\n",
            "        [ 1273],\n",
            "        [11653],\n",
            "        [16582],\n",
            "        [   19],\n",
            "        [   24],\n",
            "        [  786],\n",
            "        [ 6642],\n",
            "        [ 1445],\n",
            "        [   26],\n",
            "        [ 1545],\n",
            "        [ 7132],\n",
            "        [  344],\n",
            "        [24700],\n",
            "        [  299],\n",
            "        [18174],\n",
            "        [   22],\n",
            "        [ 4798],\n",
            "        [ 8133],\n",
            "        [  308],\n",
            "        [29098],\n",
            "        [ 8108],\n",
            "        [  519],\n",
            "        [10507],\n",
            "        [  153],\n",
            "        [ 7101],\n",
            "        [  126],\n",
            "        [ 2646],\n",
            "        [   34],\n",
            "        [   22],\n",
            "        [  117],\n",
            "        [    1],\n",
            "        [ 4039],\n",
            "        [  420],\n",
            "        [  416],\n",
            "        [  338],\n",
            "        [ 1073],\n",
            "        [11277],\n",
            "        [ 7349],\n",
            "        [  529],\n",
            "        [  758],\n",
            "        [ 7636],\n",
            "        [11586],\n",
            "        [ 5133],\n",
            "        [  727],\n",
            "        [  808],\n",
            "        [ 1600],\n",
            "        [  334],\n",
            "        [  245],\n",
            "        [  296],\n",
            "        [ 2887],\n",
            "        [12369],\n",
            "        [   47],\n",
            "        [   13]])\n",
            "tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
            "        1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
            "        1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
            "        1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
            "        1., 0., 0., 1., 0., 1., 0., 0., 1., 1.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[   35],\n",
            "        [  323],\n",
            "        [   13],\n",
            "        [  902],\n",
            "        [  410],\n",
            "        [  118],\n",
            "        [17148],\n",
            "        [  281],\n",
            "        [  388],\n",
            "        [  539],\n",
            "        [   14],\n",
            "        [   61],\n",
            "        [   14],\n",
            "        [    7],\n",
            "        [  305],\n",
            "        [ 2461],\n",
            "        [  420],\n",
            "        [  571],\n",
            "        [  278],\n",
            "        [   18],\n",
            "        [  411],\n",
            "        [  353],\n",
            "        [  497],\n",
            "        [  671],\n",
            "        [   49],\n",
            "        [  871],\n",
            "        [   22],\n",
            "        [   49],\n",
            "        [  117],\n",
            "        [  260],\n",
            "        [  661],\n",
            "        [  735],\n",
            "        [  338],\n",
            "        [ 1998],\n",
            "        [  716],\n",
            "        [  133],\n",
            "        [  524],\n",
            "        [  183],\n",
            "        [   34],\n",
            "        [  264],\n",
            "        [  859],\n",
            "        [   61],\n",
            "        [  204],\n",
            "        [    1],\n",
            "        [  579],\n",
            "        [  739],\n",
            "        [  951],\n",
            "        [  285],\n",
            "        [  397],\n",
            "        [11072],\n",
            "        [ 4317],\n",
            "        [ 1794],\n",
            "        [   59],\n",
            "        [  201],\n",
            "        [27235],\n",
            "        [  587],\n",
            "        [  288],\n",
            "        [  205],\n",
            "        [  602],\n",
            "        [   61],\n",
            "        [ 3167],\n",
            "        [  213],\n",
            "        [  573],\n",
            "        [   80],\n",
            "        [ 1240],\n",
            "        [  191],\n",
            "        [ 6971],\n",
            "        [  672],\n",
            "        [  477],\n",
            "        [  400],\n",
            "        [   56],\n",
            "        [    5],\n",
            "        [  316],\n",
            "        [  243],\n",
            "        [  333],\n",
            "        [  187],\n",
            "        [ 7521],\n",
            "        [21972],\n",
            "        [   61],\n",
            "        [   13],\n",
            "        [  520],\n",
            "        [  231],\n",
            "        [ 6918],\n",
            "        [  485],\n",
            "        [   60],\n",
            "        [  163],\n",
            "        [   88],\n",
            "        [  734],\n",
            "        [  153],\n",
            "        [ 1952],\n",
            "        [  670],\n",
            "        [  134],\n",
            "        [   30],\n",
            "        [11491],\n",
            "        [   61],\n",
            "        [   49],\n",
            "        [  129],\n",
            "        [   11],\n",
            "        [13000],\n",
            "        [   61]])\n",
            "tensor([0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
            "        1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
            "        1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,\n",
            "        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 0., 0., 1., 1., 1., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[  490],\n",
            "        [  231],\n",
            "        [ 4867],\n",
            "        [    1],\n",
            "        [  114],\n",
            "        [ 4673],\n",
            "        [   59],\n",
            "        [  136],\n",
            "        [ 1362],\n",
            "        [ 1816],\n",
            "        [   41],\n",
            "        [ 6250],\n",
            "        [  190],\n",
            "        [   47],\n",
            "        [ 1509],\n",
            "        [ 1578],\n",
            "        [  137],\n",
            "        [   81],\n",
            "        [ 1102],\n",
            "        [21832],\n",
            "        [  262],\n",
            "        [  502],\n",
            "        [    7],\n",
            "        [  318],\n",
            "        [   16],\n",
            "        [   25],\n",
            "        [  194],\n",
            "        [ 1712],\n",
            "        [ 1862],\n",
            "        [   18],\n",
            "        [  112],\n",
            "        [   63],\n",
            "        [   72],\n",
            "        [ 3446],\n",
            "        [   43],\n",
            "        [10457],\n",
            "        [ 1334],\n",
            "        [ 1218],\n",
            "        [ 4839],\n",
            "        [ 8190],\n",
            "        [12548],\n",
            "        [    8],\n",
            "        [  420],\n",
            "        [  615],\n",
            "        [   72],\n",
            "        [  102],\n",
            "        [  146],\n",
            "        [    5],\n",
            "        [ 3135],\n",
            "        [ 2089],\n",
            "        [  317],\n",
            "        [   24],\n",
            "        [  126],\n",
            "        [   87],\n",
            "        [   15],\n",
            "        [    8],\n",
            "        [ 5325],\n",
            "        [    1],\n",
            "        [ 2700],\n",
            "        [10368],\n",
            "        [ 2041],\n",
            "        [  233],\n",
            "        [  138],\n",
            "        [   61],\n",
            "        [  163],\n",
            "        [  117],\n",
            "        [ 6361],\n",
            "        [  444],\n",
            "        [  502],\n",
            "        [ 1516],\n",
            "        [   87],\n",
            "        [11093],\n",
            "        [  420],\n",
            "        [  179],\n",
            "        [   82],\n",
            "        [   28],\n",
            "        [ 3276],\n",
            "        [  720],\n",
            "        [   56],\n",
            "        [  269],\n",
            "        [ 4168],\n",
            "        [   21],\n",
            "        [  562],\n",
            "        [  295],\n",
            "        [ 2959],\n",
            "        [  438],\n",
            "        [  448],\n",
            "        [ 5014],\n",
            "        [  819],\n",
            "        [  338],\n",
            "        [ 9043],\n",
            "        [24592],\n",
            "        [20326],\n",
            "        [12931],\n",
            "        [   21],\n",
            "        [ 1265],\n",
            "        [    8],\n",
            "        [   38],\n",
            "        [   60],\n",
            "        [  429]])\n",
            "tensor([0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
            "        0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
            "        1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
            "        0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
            "        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 1., 1., 0., 1., 1., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[  631],\n",
            "        [  394],\n",
            "        [  153],\n",
            "        [ 3959],\n",
            "        [ 1008],\n",
            "        [18192],\n",
            "        [  594],\n",
            "        [26193],\n",
            "        [  438],\n",
            "        [  114],\n",
            "        [    8],\n",
            "        [  143],\n",
            "        [21595],\n",
            "        [  162],\n",
            "        [   14],\n",
            "        [   44],\n",
            "        [22872],\n",
            "        [  212],\n",
            "        [  163],\n",
            "        [ 1765],\n",
            "        [  153],\n",
            "        [ 3135],\n",
            "        [11132],\n",
            "        [  643],\n",
            "        [  162],\n",
            "        [   41],\n",
            "        [  144],\n",
            "        [   34],\n",
            "        [   10],\n",
            "        [    8],\n",
            "        [   44],\n",
            "        [ 8381],\n",
            "        [  960],\n",
            "        [26348],\n",
            "        [  702],\n",
            "        [  362],\n",
            "        [  215],\n",
            "        [13934],\n",
            "        [ 3091],\n",
            "        [  704],\n",
            "        [ 1125],\n",
            "        [  587],\n",
            "        [ 5728],\n",
            "        [19713],\n",
            "        [  639],\n",
            "        [10758],\n",
            "        [ 4063],\n",
            "        [  238],\n",
            "        [   40],\n",
            "        [  135],\n",
            "        [  680],\n",
            "        [  443],\n",
            "        [   26],\n",
            "        [   40],\n",
            "        [ 1091],\n",
            "        [24486],\n",
            "        [    1],\n",
            "        [    1],\n",
            "        [  138],\n",
            "        [  295],\n",
            "        [  206],\n",
            "        [    1],\n",
            "        [  443],\n",
            "        [   61],\n",
            "        [  948],\n",
            "        [  117],\n",
            "        [ 3680],\n",
            "        [10643],\n",
            "        [  554],\n",
            "        [   47],\n",
            "        [  312],\n",
            "        [  753],\n",
            "        [ 1083],\n",
            "        [ 1460],\n",
            "        [   41],\n",
            "        [   39],\n",
            "        [   86],\n",
            "        [ 6225],\n",
            "        [  611],\n",
            "        [   22],\n",
            "        [  355],\n",
            "        [   83],\n",
            "        [  733],\n",
            "        [   81],\n",
            "        [   41],\n",
            "        [ 1265],\n",
            "        [   61],\n",
            "        [    8],\n",
            "        [    5],\n",
            "        [  329],\n",
            "        [   82],\n",
            "        [   46],\n",
            "        [ 1397],\n",
            "        [  303],\n",
            "        [11420],\n",
            "        [   30],\n",
            "        [  535],\n",
            "        [   16],\n",
            "        [  215],\n",
            "        [  402]])\n",
            "tensor([1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
            "        0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
            "        0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
            "        0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
            "        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 1.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[10084],\n",
            "        [14183],\n",
            "        [ 2787],\n",
            "        [  584],\n",
            "        [  938],\n",
            "        [  416],\n",
            "        [   18],\n",
            "        [ 5384],\n",
            "        [   11],\n",
            "        [ 1821],\n",
            "        [    8],\n",
            "        [ 1050],\n",
            "        [  179],\n",
            "        [   70],\n",
            "        [26900],\n",
            "        [   95],\n",
            "        [ 6864],\n",
            "        [   60],\n",
            "        [    1],\n",
            "        [   60],\n",
            "        [  224],\n",
            "        [ 6240],\n",
            "        [  285],\n",
            "        [19515],\n",
            "        [  524],\n",
            "        [ 1407],\n",
            "        [  849],\n",
            "        [15136],\n",
            "        [ 1513],\n",
            "        [  215],\n",
            "        [ 1587],\n",
            "        [ 7636],\n",
            "        [ 1559],\n",
            "        [  390],\n",
            "        [  117],\n",
            "        [  494],\n",
            "        [  490],\n",
            "        [  498],\n",
            "        [ 2980],\n",
            "        [ 1358],\n",
            "        [   35],\n",
            "        [  674],\n",
            "        [  816],\n",
            "        [26602],\n",
            "        [19064],\n",
            "        [10075],\n",
            "        [  529],\n",
            "        [   16],\n",
            "        [ 1728],\n",
            "        [   88],\n",
            "        [ 4650],\n",
            "        [  975],\n",
            "        [   44],\n",
            "        [   13],\n",
            "        [   29],\n",
            "        [13535],\n",
            "        [ 9062],\n",
            "        [ 4157],\n",
            "        [   81],\n",
            "        [   49],\n",
            "        [ 6208],\n",
            "        [   61],\n",
            "        [   81],\n",
            "        [ 8722],\n",
            "        [  147],\n",
            "        [  264],\n",
            "        [    5],\n",
            "        [23802],\n",
            "        [ 1264],\n",
            "        [ 4138],\n",
            "        [ 2974],\n",
            "        [  411],\n",
            "        [ 4568],\n",
            "        [ 2260],\n",
            "        [  264],\n",
            "        [  134],\n",
            "        [  893],\n",
            "        [ 4979],\n",
            "        [26971],\n",
            "        [  199],\n",
            "        [   25],\n",
            "        [ 4797],\n",
            "        [ 1003],\n",
            "        [   33],\n",
            "        [14131],\n",
            "        [   27],\n",
            "        [   81],\n",
            "        [    4],\n",
            "        [ 1751],\n",
            "        [12173],\n",
            "        [  391],\n",
            "        [ 6033],\n",
            "        [  847],\n",
            "        [ 2716],\n",
            "        [   40],\n",
            "        [   26],\n",
            "        [ 1459],\n",
            "        [18431],\n",
            "        [  831],\n",
            "        [  400]])\n",
            "tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
            "        0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
            "        1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
            "        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[   19],\n",
            "        [   46],\n",
            "        [23928],\n",
            "        [  186],\n",
            "        [  298],\n",
            "        [   35],\n",
            "        [  117],\n",
            "        [  142],\n",
            "        [  126],\n",
            "        [ 1063],\n",
            "        [   61],\n",
            "        [  108],\n",
            "        [  811],\n",
            "        [ 4213],\n",
            "        [  345],\n",
            "        [  185],\n",
            "        [  317],\n",
            "        [  216],\n",
            "        [ 1079],\n",
            "        [   11],\n",
            "        [  163],\n",
            "        [  544],\n",
            "        [ 3954],\n",
            "        [  419],\n",
            "        [15228],\n",
            "        [  338],\n",
            "        [ 1065],\n",
            "        [ 1510],\n",
            "        [   35],\n",
            "        [ 5662],\n",
            "        [ 1863],\n",
            "        [ 1842],\n",
            "        [   16],\n",
            "        [ 6372],\n",
            "        [   28],\n",
            "        [ 5197],\n",
            "        [23023],\n",
            "        [ 5896],\n",
            "        [  329],\n",
            "        [    7],\n",
            "        [  127],\n",
            "        [  158],\n",
            "        [  634],\n",
            "        [ 5160],\n",
            "        [  889],\n",
            "        [ 3009],\n",
            "        [ 3406],\n",
            "        [ 9896],\n",
            "        [ 1404],\n",
            "        [ 5785],\n",
            "        [  135],\n",
            "        [  202],\n",
            "        [ 6060],\n",
            "        [ 2598],\n",
            "        [   28],\n",
            "        [ 4674],\n",
            "        [ 1325],\n",
            "        [   28],\n",
            "        [ 2298],\n",
            "        [  114],\n",
            "        [  428],\n",
            "        [ 1601],\n",
            "        [  858],\n",
            "        [  146],\n",
            "        [   23],\n",
            "        [   16],\n",
            "        [   19],\n",
            "        [   31],\n",
            "        [  243],\n",
            "        [22702],\n",
            "        [22985],\n",
            "        [ 6373],\n",
            "        [ 1246],\n",
            "        [  139],\n",
            "        [   81],\n",
            "        [   16],\n",
            "        [    7],\n",
            "        [   33],\n",
            "        [   13],\n",
            "        [  308],\n",
            "        [  422],\n",
            "        [  344],\n",
            "        [ 3940],\n",
            "        [  847],\n",
            "        [  323],\n",
            "        [    5],\n",
            "        [   98],\n",
            "        [  720],\n",
            "        [  292],\n",
            "        [ 7204],\n",
            "        [    9],\n",
            "        [  653],\n",
            "        [    8],\n",
            "        [  493],\n",
            "        [  264],\n",
            "        [ 3694],\n",
            "        [  268],\n",
            "        [   72],\n",
            "        [   17],\n",
            "        [  123]])\n",
            "tensor([1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
            "        0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
            "        1., 0., 1., 0., 0., 0., 1., 0., 1., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[ 3625],\n",
            "        [   35],\n",
            "        [ 9788],\n",
            "        [ 1280],\n",
            "        [  998],\n",
            "        [  446],\n",
            "        [   68],\n",
            "        [  503],\n",
            "        [ 1015],\n",
            "        [    1],\n",
            "        [  243],\n",
            "        [  139],\n",
            "        [   43],\n",
            "        [ 7029],\n",
            "        [   24],\n",
            "        [  605],\n",
            "        [   16],\n",
            "        [   40],\n",
            "        [   38],\n",
            "        [  529],\n",
            "        [10727],\n",
            "        [    8],\n",
            "        [  680],\n",
            "        [   18],\n",
            "        [  114],\n",
            "        [   26],\n",
            "        [   16],\n",
            "        [  285],\n",
            "        [   86],\n",
            "        [ 7370],\n",
            "        [  507],\n",
            "        [ 2080],\n",
            "        [    4],\n",
            "        [  191],\n",
            "        [  609],\n",
            "        [  762],\n",
            "        [ 1988],\n",
            "        [  114],\n",
            "        [  179],\n",
            "        [ 3395],\n",
            "        [  329],\n",
            "        [   11],\n",
            "        [19578],\n",
            "        [   25],\n",
            "        [    8],\n",
            "        [   80],\n",
            "        [ 2543],\n",
            "        [   18],\n",
            "        [  483],\n",
            "        [   54],\n",
            "        [  162],\n",
            "        [  317],\n",
            "        [ 2565],\n",
            "        [  117],\n",
            "        [  928],\n",
            "        [   28],\n",
            "        [11594],\n",
            "        [   16],\n",
            "        [   22],\n",
            "        [ 2175],\n",
            "        [   31],\n",
            "        [   56],\n",
            "        [  472],\n",
            "        [ 4404],\n",
            "        [12135],\n",
            "        [  994],\n",
            "        [28912],\n",
            "        [    1],\n",
            "        [  657],\n",
            "        [ 2511],\n",
            "        [  708],\n",
            "        [  154],\n",
            "        [  340],\n",
            "        [  245],\n",
            "        [  161],\n",
            "        [16347],\n",
            "        [11310],\n",
            "        [27577],\n",
            "        [   87],\n",
            "        [17716],\n",
            "        [  582],\n",
            "        [ 1111],\n",
            "        [  728],\n",
            "        [ 1103],\n",
            "        [ 7075],\n",
            "        [  262],\n",
            "        [  309],\n",
            "        [    1],\n",
            "        [  161],\n",
            "        [  182],\n",
            "        [ 2969],\n",
            "        [  193],\n",
            "        [  116],\n",
            "        [  390],\n",
            "        [  143],\n",
            "        [   24],\n",
            "        [  380],\n",
            "        [    1],\n",
            "        [12355],\n",
            "        [   61]])\n",
            "tensor([0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
            "        1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
            "        1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
            "        1., 1., 0., 0., 0., 0., 1., 1., 1., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[14059],\n",
            "        [ 3003],\n",
            "        [   47],\n",
            "        [  388],\n",
            "        [   60],\n",
            "        [  169],\n",
            "        [   11],\n",
            "        [ 8165],\n",
            "        [  144],\n",
            "        [   63],\n",
            "        [  625],\n",
            "        [   13],\n",
            "        [ 5900],\n",
            "        [   40],\n",
            "        [   29],\n",
            "        [ 1401],\n",
            "        [  194],\n",
            "        [  394],\n",
            "        [   77],\n",
            "        [  140],\n",
            "        [  443],\n",
            "        [   61],\n",
            "        [    7],\n",
            "        [  526],\n",
            "        [  585],\n",
            "        [  996],\n",
            "        [ 4563],\n",
            "        [  260],\n",
            "        [   44],\n",
            "        [  238],\n",
            "        [  212],\n",
            "        [ 2825],\n",
            "        [ 3129],\n",
            "        [10741],\n",
            "        [15296],\n",
            "        [    5],\n",
            "        [  143],\n",
            "        [  802],\n",
            "        [ 1178],\n",
            "        [   30],\n",
            "        [ 1091],\n",
            "        [ 5878],\n",
            "        [  727],\n",
            "        [  653],\n",
            "        [13275],\n",
            "        [    7],\n",
            "        [ 4967],\n",
            "        [  218],\n",
            "        [ 3613],\n",
            "        [  193],\n",
            "        [   45],\n",
            "        [  380],\n",
            "        [    8],\n",
            "        [15434],\n",
            "        [ 1761],\n",
            "        [    1],\n",
            "        [    1],\n",
            "        [ 1392],\n",
            "        [  117],\n",
            "        [   18],\n",
            "        [ 5168],\n",
            "        [ 6876],\n",
            "        [  859],\n",
            "        [ 4893],\n",
            "        [ 8402],\n",
            "        [   26],\n",
            "        [  274],\n",
            "        [  928],\n",
            "        [ 1670],\n",
            "        [  785],\n",
            "        [   74],\n",
            "        [ 3404],\n",
            "        [ 7921],\n",
            "        [    1],\n",
            "        [25493],\n",
            "        [  796],\n",
            "        [21388],\n",
            "        [   44],\n",
            "        [  444],\n",
            "        [ 9652],\n",
            "        [   28],\n",
            "        [ 1210],\n",
            "        [   88],\n",
            "        [   34],\n",
            "        [ 2402],\n",
            "        [  230],\n",
            "        [  306],\n",
            "        [ 5622],\n",
            "        [ 3129],\n",
            "        [  117],\n",
            "        [  881],\n",
            "        [   16],\n",
            "        [   40],\n",
            "        [ 5672],\n",
            "        [  524],\n",
            "        [   25],\n",
            "        [   11],\n",
            "        [   25],\n",
            "        [  105],\n",
            "        [ 6773]])\n",
            "tensor([0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0.,\n",
            "        1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
            "        0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
            "        1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 1., 0., 1., 1., 1., 1., 1.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[ 7592],\n",
            "        [ 5441],\n",
            "        [14728],\n",
            "        [   26],\n",
            "        [  153],\n",
            "        [  370],\n",
            "        [   13],\n",
            "        [ 4543],\n",
            "        [  134],\n",
            "        [    8],\n",
            "        [   16],\n",
            "        [  194],\n",
            "        [   87],\n",
            "        [  907],\n",
            "        [17537],\n",
            "        [ 1244],\n",
            "        [  212],\n",
            "        [18564],\n",
            "        [ 1576],\n",
            "        [    3],\n",
            "        [    8],\n",
            "        [  754],\n",
            "        [ 1206],\n",
            "        [  361],\n",
            "        [ 1293],\n",
            "        [  615],\n",
            "        [   98],\n",
            "        [  114],\n",
            "        [ 1005],\n",
            "        [ 1145],\n",
            "        [  820],\n",
            "        [ 9562],\n",
            "        [  537],\n",
            "        [  155],\n",
            "        [   61],\n",
            "        [  698],\n",
            "        [    2],\n",
            "        [ 8721],\n",
            "        [ 1271],\n",
            "        [   41],\n",
            "        [  322],\n",
            "        [ 6353],\n",
            "        [  193],\n",
            "        [   63],\n",
            "        [  136],\n",
            "        [  525],\n",
            "        [26302],\n",
            "        [ 6080],\n",
            "        [22989],\n",
            "        [24875],\n",
            "        [  519],\n",
            "        [  393],\n",
            "        [   10],\n",
            "        [  990],\n",
            "        [  355],\n",
            "        [ 1280],\n",
            "        [    7],\n",
            "        [ 3080],\n",
            "        [  117],\n",
            "        [ 1036],\n",
            "        [   11],\n",
            "        [ 3877],\n",
            "        [ 4731],\n",
            "        [  838],\n",
            "        [13426],\n",
            "        [12649],\n",
            "        [   44],\n",
            "        [ 5167],\n",
            "        [  295],\n",
            "        [12848],\n",
            "        [  146],\n",
            "        [   76],\n",
            "        [   35],\n",
            "        [   26],\n",
            "        [   11],\n",
            "        [  101],\n",
            "        [ 8251],\n",
            "        [  740],\n",
            "        [   16],\n",
            "        [  421],\n",
            "        [  126],\n",
            "        [   77],\n",
            "        [    1],\n",
            "        [  490],\n",
            "        [   44],\n",
            "        [   90],\n",
            "        [    4],\n",
            "        [   29],\n",
            "        [  789],\n",
            "        [ 6174],\n",
            "        [ 4996],\n",
            "        [  149],\n",
            "        [ 5355],\n",
            "        [15132],\n",
            "        [ 7710],\n",
            "        [   23],\n",
            "        [  693],\n",
            "        [  950],\n",
            "        [  354],\n",
            "        [   44]])\n",
            "tensor([1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
            "        1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
            "        1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1.,\n",
            "        1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
            "        0., 0., 0., 1., 1., 1., 0., 1., 1., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[   13],\n",
            "        [  484],\n",
            "        [  238],\n",
            "        [    1],\n",
            "        [   16],\n",
            "        [  198],\n",
            "        [26566],\n",
            "        [ 1625],\n",
            "        [28071],\n",
            "        [   75],\n",
            "        [ 1369],\n",
            "        [19294],\n",
            "        [   13],\n",
            "        [  265],\n",
            "        [   56],\n",
            "        [  483],\n",
            "        [   25],\n",
            "        [   21],\n",
            "        [   11],\n",
            "        [  143],\n",
            "        [28842],\n",
            "        [   49],\n",
            "        [   41],\n",
            "        [  436],\n",
            "        [ 4656],\n",
            "        [ 1326],\n",
            "        [  985],\n",
            "        [ 3273],\n",
            "        [  789],\n",
            "        [   18],\n",
            "        [   61],\n",
            "        [   83],\n",
            "        [  168],\n",
            "        [16813],\n",
            "        [ 1093],\n",
            "        [  117],\n",
            "        [  711],\n",
            "        [ 5972],\n",
            "        [ 5145],\n",
            "        [ 3180],\n",
            "        [ 1016],\n",
            "        [28164],\n",
            "        [  281],\n",
            "        [  169],\n",
            "        [ 1892],\n",
            "        [  160],\n",
            "        [   78],\n",
            "        [ 1016],\n",
            "        [   84],\n",
            "        [   81],\n",
            "        [   10],\n",
            "        [   39],\n",
            "        [ 5964],\n",
            "        [   72],\n",
            "        [   72],\n",
            "        [ 1151],\n",
            "        [  213],\n",
            "        [  679],\n",
            "        [ 6402],\n",
            "        [   56],\n",
            "        [ 2308],\n",
            "        [ 9657],\n",
            "        [ 6258],\n",
            "        [  776],\n",
            "        [   18],\n",
            "        [  429],\n",
            "        [   16],\n",
            "        [   18],\n",
            "        [  143],\n",
            "        [  166],\n",
            "        [ 5687],\n",
            "        [   82],\n",
            "        [ 5030],\n",
            "        [   60],\n",
            "        [ 9247],\n",
            "        [   35],\n",
            "        [  870],\n",
            "        [    8],\n",
            "        [ 1215],\n",
            "        [   13],\n",
            "        [   25],\n",
            "        [   25],\n",
            "        [   16],\n",
            "        [   25],\n",
            "        [   28],\n",
            "        [ 3076],\n",
            "        [ 2382],\n",
            "        [  507],\n",
            "        [  879],\n",
            "        [   15],\n",
            "        [   14],\n",
            "        [ 1344],\n",
            "        [  642],\n",
            "        [  179],\n",
            "        [   34],\n",
            "        [    7],\n",
            "        [  287],\n",
            "        [ 1683],\n",
            "        [15964],\n",
            "        [21476]])\n",
            "tensor([1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
            "        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
            "        1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
            "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[  537],\n",
            "        [  308],\n",
            "        [  287],\n",
            "        [ 1879],\n",
            "        [10895],\n",
            "        [  114],\n",
            "        [18930],\n",
            "        [ 1358],\n",
            "        [ 1871],\n",
            "        [ 8137],\n",
            "        [  340],\n",
            "        [  544],\n",
            "        [  177],\n",
            "        [   25],\n",
            "        [ 1589],\n",
            "        [   57],\n",
            "        [ 7432],\n",
            "        [    8],\n",
            "        [  111],\n",
            "        [   16],\n",
            "        [   60],\n",
            "        [   94],\n",
            "        [  146],\n",
            "        [    1],\n",
            "        [ 6507],\n",
            "        [15247],\n",
            "        [11300],\n",
            "        [  160],\n",
            "        [   81],\n",
            "        [ 1051],\n",
            "        [  167],\n",
            "        [ 1238],\n",
            "        [  483],\n",
            "        [  347],\n",
            "        [  191],\n",
            "        [    1],\n",
            "        [   28],\n",
            "        [  493],\n",
            "        [   11],\n",
            "        [18501],\n",
            "        [  483],\n",
            "        [  492],\n",
            "        [  105],\n",
            "        [  251],\n",
            "        [  483],\n",
            "        [28938],\n",
            "        [  414],\n",
            "        [   16],\n",
            "        [  654],\n",
            "        [14862],\n",
            "        [  194],\n",
            "        [   25],\n",
            "        [   61],\n",
            "        [  117],\n",
            "        [  473],\n",
            "        [  621],\n",
            "        [  760],\n",
            "        [   61],\n",
            "        [   25],\n",
            "        [  336],\n",
            "        [  680],\n",
            "        [   14],\n",
            "        [   65],\n",
            "        [  250],\n",
            "        [  117],\n",
            "        [18366],\n",
            "        [    1],\n",
            "        [    8],\n",
            "        [  122],\n",
            "        [   56],\n",
            "        [  137],\n",
            "        [  139],\n",
            "        [  116],\n",
            "        [ 4027],\n",
            "        [  928],\n",
            "        [   23],\n",
            "        [  153],\n",
            "        [   16],\n",
            "        [  773],\n",
            "        [  580],\n",
            "        [ 2109],\n",
            "        [  563],\n",
            "        [  122],\n",
            "        [  108],\n",
            "        [  146],\n",
            "        [ 1399],\n",
            "        [   26],\n",
            "        [  134],\n",
            "        [   87],\n",
            "        [  556],\n",
            "        [  577],\n",
            "        [   61],\n",
            "        [   49],\n",
            "        [10355],\n",
            "        [   57],\n",
            "        [  116],\n",
            "        [  118],\n",
            "        [ 1435],\n",
            "        [ 6007],\n",
            "        [ 1805]])\n",
            "tensor([0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
            "        1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
            "        0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
            "        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
            "        0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 1., 0., 1.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[  137],\n",
            "        [  104],\n",
            "        [17379],\n",
            "        [ 4748],\n",
            "        [12667],\n",
            "        [  144],\n",
            "        [   77],\n",
            "        [  305],\n",
            "        [  305],\n",
            "        [    7],\n",
            "        [  317],\n",
            "        [ 4775],\n",
            "        [  660],\n",
            "        [  191],\n",
            "        [   13],\n",
            "        [ 1306],\n",
            "        [  334],\n",
            "        [   52],\n",
            "        [  153],\n",
            "        [   57],\n",
            "        [  212],\n",
            "        [    8],\n",
            "        [   23],\n",
            "        [  695],\n",
            "        [  117],\n",
            "        [  122],\n",
            "        [   46],\n",
            "        [   99],\n",
            "        [   33],\n",
            "        [  244],\n",
            "        [   67],\n",
            "        [   79],\n",
            "        [  232],\n",
            "        [ 1538],\n",
            "        [   68],\n",
            "        [  213],\n",
            "        [ 1177],\n",
            "        [    5],\n",
            "        [  381],\n",
            "        [ 2067],\n",
            "        [  117],\n",
            "        [11569],\n",
            "        [    1],\n",
            "        [ 2519],\n",
            "        [   40],\n",
            "        [26076],\n",
            "        [ 1559],\n",
            "        [ 5889],\n",
            "        [ 2505],\n",
            "        [  618],\n",
            "        [   10],\n",
            "        [   16],\n",
            "        [ 5384],\n",
            "        [  760],\n",
            "        [ 1714],\n",
            "        [ 1733],\n",
            "        [    1],\n",
            "        [ 2470],\n",
            "        [   61],\n",
            "        [ 2825],\n",
            "        [   26],\n",
            "        [ 3403],\n",
            "        [  230],\n",
            "        [  419],\n",
            "        [   30],\n",
            "        [   69],\n",
            "        [   96],\n",
            "        [  142],\n",
            "        [28129],\n",
            "        [   35],\n",
            "        [  618],\n",
            "        [   10],\n",
            "        [   87],\n",
            "        [17504],\n",
            "        [  750],\n",
            "        [   14],\n",
            "        [ 6272],\n",
            "        [   25],\n",
            "        [   65],\n",
            "        [23630],\n",
            "        [11538],\n",
            "        [ 1618],\n",
            "        [  163],\n",
            "        [  351],\n",
            "        [ 5914],\n",
            "        [ 6320],\n",
            "        [ 1183],\n",
            "        [   46],\n",
            "        [ 3935],\n",
            "        [  114],\n",
            "        [ 3076],\n",
            "        [  641],\n",
            "        [20534],\n",
            "        [ 1880],\n",
            "        [20301],\n",
            "        [ 1174],\n",
            "        [   11],\n",
            "        [ 3441],\n",
            "        [  611],\n",
            "        [ 1151]])\n",
            "tensor([1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
            "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
            "        1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
            "        1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
            "        1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
            "        1., 0., 1., 1., 0., 0., 1., 0., 1., 1.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[  174],\n",
            "        [ 4261],\n",
            "        [   33],\n",
            "        [27835],\n",
            "        [   15],\n",
            "        [ 1805],\n",
            "        [   61],\n",
            "        [ 4059],\n",
            "        [27457],\n",
            "        [ 2808],\n",
            "        [   60],\n",
            "        [23730],\n",
            "        [   33],\n",
            "        [  186],\n",
            "        [ 1066],\n",
            "        [    5],\n",
            "        [11864],\n",
            "        [   72],\n",
            "        [ 1125],\n",
            "        [ 7022],\n",
            "        [   41],\n",
            "        [  302],\n",
            "        [23026],\n",
            "        [ 9192],\n",
            "        [ 1031],\n",
            "        [  194],\n",
            "        [   21],\n",
            "        [    7],\n",
            "        [27438],\n",
            "        [    1],\n",
            "        [ 4904],\n",
            "        [   30],\n",
            "        [  232],\n",
            "        [ 2140],\n",
            "        [ 8540],\n",
            "        [ 2047],\n",
            "        [  234],\n",
            "        [  572],\n",
            "        [   16],\n",
            "        [   89],\n",
            "        [   43],\n",
            "        [  498],\n",
            "        [  600],\n",
            "        [   59],\n",
            "        [   77],\n",
            "        [   84],\n",
            "        [ 2734],\n",
            "        [ 1790],\n",
            "        [10884],\n",
            "        [ 2808],\n",
            "        [   16],\n",
            "        [   11],\n",
            "        [  129],\n",
            "        [   67],\n",
            "        [   47],\n",
            "        [    5],\n",
            "        [23162],\n",
            "        [ 2147],\n",
            "        [  149],\n",
            "        [   37],\n",
            "        [ 9968],\n",
            "        [  305],\n",
            "        [   81],\n",
            "        [  163],\n",
            "        [  151],\n",
            "        [   77],\n",
            "        [    1],\n",
            "        [  108],\n",
            "        [15309],\n",
            "        [  246],\n",
            "        [   23],\n",
            "        [  117],\n",
            "        [ 4838],\n",
            "        [   23],\n",
            "        [  292],\n",
            "        [   51],\n",
            "        [22920],\n",
            "        [  502],\n",
            "        [  640],\n",
            "        [ 1187],\n",
            "        [  740],\n",
            "        [22248],\n",
            "        [  498],\n",
            "        [12599],\n",
            "        [26853],\n",
            "        [  818],\n",
            "        [  435],\n",
            "        [  971],\n",
            "        [  174],\n",
            "        [    4],\n",
            "        [14161],\n",
            "        [   72],\n",
            "        [   43],\n",
            "        [  104],\n",
            "        [  902],\n",
            "        [ 1724],\n",
            "        [  117],\n",
            "        [   89],\n",
            "        [   14],\n",
            "        [ 2049]])\n",
            "tensor([1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
            "        0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
            "        1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
            "        1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
            "        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[  153],\n",
            "        [   52],\n",
            "        [  141],\n",
            "        [   16],\n",
            "        [  323],\n",
            "        [   60],\n",
            "        [  114],\n",
            "        [   61],\n",
            "        [ 8262],\n",
            "        [  243],\n",
            "        [  808],\n",
            "        [ 2685],\n",
            "        [  537],\n",
            "        [  418],\n",
            "        [    1],\n",
            "        [15280],\n",
            "        [  296],\n",
            "        [  132],\n",
            "        [   33],\n",
            "        [ 1059],\n",
            "        [ 4570],\n",
            "        [   21],\n",
            "        [  402],\n",
            "        [ 5378],\n",
            "        [ 1863],\n",
            "        [   75],\n",
            "        [ 3257],\n",
            "        [ 4024],\n",
            "        [   68],\n",
            "        [ 5642],\n",
            "        [ 1935],\n",
            "        [  143],\n",
            "        [   40],\n",
            "        [16116],\n",
            "        [  802],\n",
            "        [10913],\n",
            "        [  675],\n",
            "        [ 1151],\n",
            "        [ 7420],\n",
            "        [  256],\n",
            "        [ 2083],\n",
            "        [   44],\n",
            "        [ 1991],\n",
            "        [  551],\n",
            "        [   42],\n",
            "        [   14],\n",
            "        [ 2859],\n",
            "        [ 1690],\n",
            "        [  307],\n",
            "        [  391],\n",
            "        [  104],\n",
            "        [   52],\n",
            "        [   40],\n",
            "        [  268],\n",
            "        [  246],\n",
            "        [ 1308],\n",
            "        [  125],\n",
            "        [ 3290],\n",
            "        [ 6990],\n",
            "        [   18],\n",
            "        [   28],\n",
            "        [  342],\n",
            "        [ 1004],\n",
            "        [    8],\n",
            "        [  829],\n",
            "        [ 4259],\n",
            "        [ 2778],\n",
            "        [  401],\n",
            "        [  101],\n",
            "        [16417],\n",
            "        [ 3542],\n",
            "        [ 1741],\n",
            "        [25877],\n",
            "        [    8],\n",
            "        [ 6394],\n",
            "        [ 4003],\n",
            "        [27284],\n",
            "        [  293],\n",
            "        [ 5966],\n",
            "        [  134],\n",
            "        [  243],\n",
            "        [   13],\n",
            "        [   35],\n",
            "        [ 1084],\n",
            "        [  153],\n",
            "        [   33],\n",
            "        [ 2694],\n",
            "        [    4],\n",
            "        [ 1073],\n",
            "        [  201],\n",
            "        [ 9326],\n",
            "        [   99],\n",
            "        [  126],\n",
            "        [    5],\n",
            "        [   35],\n",
            "        [ 1359],\n",
            "        [  402],\n",
            "        [ 5672],\n",
            "        [  687],\n",
            "        [ 1020]])\n",
            "tensor([1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
            "        1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
            "        0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
            "        1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
            "        0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 1., 1., 1.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "tensor([[    7],\n",
            "        [ 1793],\n",
            "        [  527],\n",
            "        [   75],\n",
            "        [   99],\n",
            "        [ 1012],\n",
            "        [19457],\n",
            "        [   83],\n",
            "        [  229],\n",
            "        [  178],\n",
            "        [12379],\n",
            "        [    7],\n",
            "        [   47],\n",
            "        [16621],\n",
            "        [11127],\n",
            "        [  477],\n",
            "        [   16],\n",
            "        [  906],\n",
            "        [ 1541],\n",
            "        [  246],\n",
            "        [ 1919],\n",
            "        [    5],\n",
            "        [   72],\n",
            "        [    5],\n",
            "        [    1],\n",
            "        [ 1429],\n",
            "        [   44],\n",
            "        [ 3482],\n",
            "        [   29],\n",
            "        [   49],\n",
            "        [  190],\n",
            "        [  628],\n",
            "        [    1],\n",
            "        [ 7276],\n",
            "        [  213],\n",
            "        [    1],\n",
            "        [ 4398],\n",
            "        [ 3634],\n",
            "        [   46],\n",
            "        [  310],\n",
            "        [   47],\n",
            "        [18660],\n",
            "        [  918],\n",
            "        [  388],\n",
            "        [ 1314],\n",
            "        [   43],\n",
            "        [26205],\n",
            "        [ 1544],\n",
            "        [  502],\n",
            "        [22142],\n",
            "        [  140],\n",
            "        [24311],\n",
            "        [ 2106],\n",
            "        [   87],\n",
            "        [  134],\n",
            "        [22816],\n",
            "        [  312],\n",
            "        [   16],\n",
            "        [  990],\n",
            "        [  306],\n",
            "        [   64],\n",
            "        [  997],\n",
            "        [   13],\n",
            "        [  374],\n",
            "        [ 9052],\n",
            "        [   69],\n",
            "        [  598],\n",
            "        [    5],\n",
            "        [  157],\n",
            "        [  554],\n",
            "        [ 8328],\n",
            "        [  967],\n",
            "        [  112],\n",
            "        [ 1016],\n",
            "        [   61],\n",
            "        [   21],\n",
            "        [   49],\n",
            "        [ 9954],\n",
            "        [   24],\n",
            "        [   78],\n",
            "        [  571],\n",
            "        [ 3283],\n",
            "        [  585],\n",
            "        [   61],\n",
            "        [29019],\n",
            "        [ 4327],\n",
            "        [  160],\n",
            "        [  578],\n",
            "        [  224],\n",
            "        [  329],\n",
            "        [ 1038],\n",
            "        [  842],\n",
            "        [10233],\n",
            "        [ 1188],\n",
            "        [16677],\n",
            "        [  762],\n",
            "        [  318],\n",
            "        [19761],\n",
            "        [  395],\n",
            "        [ 5071]])\n",
            "tensor([0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
            "        1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
            "        0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
            "        1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
            "        1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
            "        0., 1., 1., 0., 0., 0., 0., 0., 1., 0.], device='cuda:0',\n",
            "       grad_fn=<RoundBackward0>)\n",
            "Test loss: 0.722\n",
            "Test accuracy: 0.640\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <h2>LSTM Intersection </h2>"
      ],
      "metadata": {
        "id": "c12tYDXB-kvg"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv('drive/MyDrive/nlp_proj/hindi_test.csv')\n",
        "\n",
        "for i in range(len(test_data)):\n",
        "    test_data['text'][i] = emoj.sub(r'', test_data['text'][i])\n",
        "\n",
        "\n",
        "test_data['text'] =  [re.sub(r'[?|$|.|!|।|,|:|;|]','', str(x)) for x in test_data['text']]\n",
        "test_df = test_data\n",
        "\n",
        "test_df['sentence_without_stopwords'] = test_df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (final_stop_words)]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tx3yvtxQGP6e",
        "outputId": "36e32698-e65f-4625-ab17-bb35a69570f8"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-79-374155fd92fe>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_data['text'][i] = emoj.sub(r'', test_data['text'][i])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def intersection(df1,df2):\n",
        "  intersect = np.intersect1d(df1,df2)\n",
        "  print(len(intersect))\n",
        "\n",
        "print(temp_train_x)\n",
        "intersection(temp_train_x,test_df['sentence_without_stopwords'])\n",
        "intersection(temp_valid_x,test_df['sentence_without_stopwords'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNzeFH3JGQ7D",
        "outputId": "f8a37e4d-bd95-432c-8e0e-610efd9c3054"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8411     तुम हाथ उठा गले लगाया क्या सोचा तुम्हारी इज्जत...\n",
            "20110                दम गलत देश धर्म बचेगा रोटी कपड़ा मकान\n",
            "12576                           वेरी गुड मेरी नन्ही सी परी\n",
            "1960     चुतियो तुम्हारे सरीखे दोगले लोगो धर्म मज़ाक बन...\n",
            "14265                                    हाय जानू हाय जानू\n",
            "                               ...                        \n",
            "6761                              साला चुनाव आता तभी हादसा\n",
            "10392                                 सन 2022 कॉमेडी 2 साल\n",
            "1565     चाचा जी हम सारे वीडियो डाले कमेंट करिए अच्छा-अ...\n",
            "18455    आज मेरी ड्रीम मैरिज एनिवर्सरी पिछले साल आज दिन...\n",
            "14011    किसानो भारत सरकार बात करनी राजनीती कांग्रेश मि...\n",
            "Name: sentence_without_stopwords, Length: 4036, dtype: object\n",
            "41\n",
            "99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EnBIYeKHG3gl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}